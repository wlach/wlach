<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8" />
    <title>Posts tagged 'FirefoxOS' (page 2)</title>
    <meta name="description" content="Posts tagged 'FirefoxOS' (page 2)" />
    <meta name="author" content="William Lachance" />
    <meta name="keywords" content="FirefoxOS" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="/favicon.ico" />
    <link rel="canonical" href="https://wrla.ch/tags/FirefoxOS-2.html" />

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="/css/style.css" />
    <link
      rel="stylesheet"
      type="text/css"
      href="/css/pygments.css"
    />
    <link
      rel="stylesheet"
      type="text/css"
      href="/css/scribble.css"
    />
    <!-- Feeds -->
    <link
      rel="alternate"
      type="application/atom+xml"
      href="/feeds/FirefoxOS.atom.xml"
      title="Atom Feed"
    />
    <link
      rel="alternate"
      type="application/rss+xml"
      href="/feeds/FirefoxOS.rss.xml"
      title="RSS Feed"
    />
    <!-- JS -->
    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-xxxxx', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <nav
      class="flex items-center justify-between flex-wrap bg-gray-800 py-1 px-8"
    >
      <div class="flex items-center flex-shrink-0 text-gray-400 mr-6">
        <div class="p-1">
          <a href="/index.html"
            ><img
              src="/img/wlach_icon.png"
              width="32"
              height="32"
              class="p rounded"
          /></a>
        </div>
        <div class="p-1">
          <a
            href="/index.html"
            class="text-gray-200 font-semibold text-xl tracking-tight hover:text-white"
            >wlach log</a
          >
        </div>
      </div>
      <div class="flex-grow lg:flex lg:items-center">
        <div class="text-sm lg:flex-grow">
          <a
            href="/About.html"
            class="mt-4 lg:inline-block lg:mt-0 hover:text-white mr-4 text-gray-600"
          >
            About</a>
          <a
            class="mt-4 lg:inline-block lg:mt-0 text-gray-600 hover:text-white mr-4"
            href="/feeds/FirefoxOS.atom.xml"
            >Atom</a
          >
          <a
            class="mt-4 lg:inline-block lg:mt-0 text-gray-600 hover:text-white mr-4"
            href="/feeds/FirefoxOS.rss.xml"
            >RSS</a
          >
        </div>
      </div>
    </nav>
    <div id="content" class="container max-w-screen-md px-8 py-4 mx-auto">
       <p class="less-important">Showing posts tagged <em>FirefoxOS</em></p>  <article>
  <header>
    <h2><a href="/blog/2013/03/documentation-for-mozdevice/">Documentation for mozdevice</a></h2>
    <p class="index-date">Mar 11th, 2013</p>
    <p><span class="tags"><a href="/tags/Android.html">Android</a>  <a href="/tags/ateam.html">ateam</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p>Just wanted to give a quick heads up that as part of the ateam&rsquo;s ongoing effort to improve the documentation of our automated testing infrastructure, we now have <a href="https://mozbase.readthedocs.org/en/latest/mozdevice.html">online documentation</a> for mozdevice, the python library we use for interacting with Android- and FirefoxOS-based devices in automated testing.</p>

<p>Mozdevice is used in pretty much every one of our testing frameworks that has mobile support, including mochitest, reftest, <a href="https://wiki.mozilla.org/Buildbot/Talos">talos</a>, <a href="https://github.com/mozilla/autophone">autophone</a>, and <a href="https://wiki.mozilla.org/Project_Eideticker">eideticker</a>. Additionally, mozdevice is used by release engineering to clean up, monitor, and otherwise manage 
 <strike>our hundred-odd</strike> the 1200*** tegra and panda development boards that we use in <a href="http://tbpl.mozilla.org">tbpl</a>. See <a href="https://hg.mozilla.org/build/tools/file/tip/sut_tools">sut_tools</a> (old, buildbot-based, what we currently use) and <a href="https://github.com/mozilla/mozpool">mozpool</a> (the new and shiny future).</p>

<ul>
 <li>Thanks to Dustin Mitchell for the correction.</li></ul> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/02/finding-a-camera-for-eideticker/">Finding a camera for Eideticker</a></h2>
    <p class="index-date">Feb 19th, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p><em>[ For more information on the Eideticker software I&rsquo;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>Ok, so as I mentioned <a href="http://wrla.ch/blog/2013/02/eideticker-for-firefoxos/">last time</a> I&rsquo;ve been looking into making Eideticker work for devices without native HDMI output by capturing their output with some kind of camera. So far I&rsquo;ve tried four different DSLRs for this task, which have all been inadequate for different reasons. I was originally just going to write an email about this to a few concerned parties, but then figured I may as well structure it into a blog post. Maybe someone will find it useful (or better yet, have some ideas.)</p>

<p><strong>Elmo MO&ndash;1</strong></p>

<p>This is the device I mentioned last time. Easy to set up, plays nicely with the Decklink capture card we&rsquo;re using for Eideticker. It seemed almost perfect, except for that:</p>

<ol>
 <li>The image quality is <em>really</em> bad (beaten even by $200 standard digital camera). Tons of noise, picture quality really bad. Not *necessarily* a deal breaker, but it still sucks.</li>
 <li>More importantly, there seems to be no way of turning off the auto white balance adjustment. This makes automated image analysis impossible if the picture changes, as is highlighted in this video:  
  <video width="400px" src="/files/eideticker/elmo-white-balance-problem.webm" controls="controls"></video></li></ol>

<p><strong>Canon Rebel T4i</strong></p>

<p>This is the first camera that was recommended to me at the camera shop I&rsquo;ve been going to. It does have an HDMI output signal, but it&rsquo;s not &ldquo;clean&rdquo;. This <a href="http://www.hireacamera.com/blog/index.asp?post=canon-eos-650d--hdmi-explained">blog post</a> explains the details better than I could. Next.</p>

<p><strong>Nikon D600</strong></p>

<p>Supposedly does native clean 720p output, but unfortunately the <a href="http://vimeo.com/49952287">output is in a &ldquo;box&rdquo;</a> so isn&rsquo;t recognized by the Decklink cards that we&rsquo;re using (which insist on a full 1280&#215;720 HDMI signal to work). Next.</p>

<p><strong>Nikon D800</strong></p>

<p>It is possible to configure this one to not put a box around the output, so the Decklink card does recognize it. Except that the camera shuts off the HDMI signal whenever the input parameters change on the card or the signal input is turned on, which essentially makes it useless for Eideticker (this happens every time we start the Eideticker harness). Quite a shame, as the HDMI signal is quite nice otherwise.</p>

<p>&#8212;</p>

<p>To be clear, with the exception of the Elmo all the devices above seem like fine cameras, and should more than do for manual captures of B2G or Android phones (which is something we probably want to do anyway). But for Eideticker, we need something that works in automation, and none of the above fit the bill. I guess I could explore using a &ldquo;real&rdquo; video camera as opposed to a DSLR acting like one, though I suspect I might run into some of the same sorts of issues depending on how the HDMI output of those devices behaves.</p>

<p>Part of me wonders whether a custom solution wouldn&rsquo;t work better. How complicated could it be to construct your own digital camera anyway? ðŸ˜‰ Hook up a fancy camera sensor to a <a href="http://pandaboard.org">pandaboard</a>, get it to output through the HDMI port, and then we&rsquo;re set? Or better yet, maybe just get a fancy webcam like the <a href="http://en.wikipedia.org/wiki/PlayStation_Eye">Playstation Eye</a> and hook it up directly to a computer? That would eliminate the need for our expensive video capture card setup altogether.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/02/eideticker-for-firefoxos/">Eideticker for FirefoxOS</a></h2>
    <p class="index-date">Feb 1st, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p><em>[ For more information on the Eideticker software I&rsquo;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>Here&rsquo;s a long overdue update on where we&rsquo;re at with Eideticker for FirefoxOS. While we&rsquo;ve had a good amount of success getting <a href="http://eideticker.wrla.ch">useful, actionable data</a> out of Eideticker for Android, so far we haven&rsquo;t been able to replicate that success for FirefoxOS. This is not for lack of trying: first, <a href="http://nakubu.com/">Malini Das</a> and then me have been working at it since summer 2012.</p>

<p>When it comes right down to it, instrumenting Eideticker for B2G is just a whole lot more complex. On Android, we could take the operating system (including support for all the things we needed, like HDMI capture) as a given. The only tricky part was instrumenting the capture so the right things happened at the right moment. With FirefoxOS, we need to run these tests on entire builds of a whole operating system which was constantly changing. Not nearly as simple. That said, I&rsquo;m starting to see light at the end of the tunnel.</p>

<p><strong>Platforms</strong></p>

<p>We initially selected the <a href="http://pandaboard.org">pandaboard</a> as the main device to use for eideticker testing, for two reasons. First, it&rsquo;s the same hardware platform we&rsquo;re targeting for other b2g testing in tbpl (mochitest, reftest, etc.), and is the platform we&rsquo;re using for running Gaia UI tests. Second, unlike every other device that we&rsquo;re prototyping FirefoxOS on (to my knowledge), it has HDMI-out capability, so we can directly interface it with the Eideticker video capture setup.</p>

<p>However, the panda also has some serious shortcomings. First, it&rsquo;s obviously not a platform we&rsquo;re shipping, so the performance we&rsquo;re seeing from it is subject to different factors that we might not see with a phone actually shipped to users. For the same reason, we&rsquo;ve had many problems getting B2G running reliably on it, as it&rsquo;s not something most developers have been hacking on a day to day basis. Thanks to the heroic efforts of Thomas Zimmerman, we&rsquo;ve mostly got things working ok now, but it was a fairly long road to get here (several months last fall).</p>

<p>More recently, we became aware of something called an <a href="http://www.elmousa.com/">Elmo</a> which might let us combine
 <br />the best of both worlds. An elmo is really just a tiny mounted video camera with a bunch of outputs, and is I understand most commonly used to project documents in a classroom/presentation setting. However, it seems to do a great job of capturing mobile phones in action as well.</p>

<video width="400px" src="/files/eideticker/startup-test-elmo.webm" controls="controls"></video>

<p>The nice thing about using an external camera for the video capture part of eideticker is that we are no longer limited to devices with HDMI out &#8212; we can run the standard set of automated tests on ANYTHING. We&rsquo;ve already used this to some success in getting some videos of FirefoxOS startup times versus Android on the Unagi (a development phone that we&rsquo;re using internally) for manual analysis. Automating this process may be trickier because of the fact that the video capture is no longer &ldquo;perfect&rdquo;, but we may be able to work around that (more discussion about this later).</p>

<p><strong>FirefoxOS web page tests</strong></p>

<p>These are the same tests we run on Android. They should give us an idea of roughly where our performance when browsing / panning web sites like CNN. So far, I&rsquo;ve only run these tests on the Pandaboard and they are INCREDIBLY slow (like 1&ndash;3 frames per second when scrolling). So much so that I have to think there is something broken about our hardware acceleration on this platform.</p>

<p><strong>FirefoxOS application tests</strong></p>

<p>These are some new tests written in a framework that allows you to script arbitrary interactions in FirefoxOS, like launching applications or opening the task switcher.</p>

<p>I&rsquo;m pretty happy with this. It seems to work well. The only problems I&rsquo;m seeing with this is with the platform we&rsquo;re running these tests on. With the pandaboard, applications look weird (since the screen resolution doesn&rsquo;t remotely resemble the 320&#215;480 resolution on our current devices) and performance is abysmal. Take, for example, this capture of application switching performance, which operates only at roughly 3&ndash;4 fps:</p>

<video width="400px" src="/files/eideticker/b2g-appswitching-video.webm" controls="controls"></video>

<p><strong>So what now?</strong></p>

<p>I&rsquo;m not 100% sure yet (partly it will depend on what others say as well as my own investigation), but I have a feeling that capturing video of real devices running FirefoxOS using the Elmo is the way forward. First, the hardware and driver situation will be much more representative of what we&rsquo;ll actually be shipping to users. Second, we can flash new builds of FirefoxOS onto them automatically, unlike the pandaboards where you currently either need to manually flash and reset (a time consuming and error prone process) or set up an instance of <a href="https://github.com/djmitche/mozpool">mozpool</a> (which I understand is quite complicated).</p>

<p>The main use case I see with eideticker-on-panda would be where we wanted to run a suite of tests on checkin (in tbpl-like fashion) and we&rsquo;d need to scale to many devices. While cool, this sounds like an expensive project (both in terms of time and hardware) and I think we&rsquo;d do better with getting something slightly smaller-scale running first.</p>

<p>So, the real question is whether or not the capture produced by the Elmo is amenable to the same analysis that we do on the raw HDMI output. At the very least, some of eideticker&rsquo;s image analysis code will have to be adapted to handle a much &ldquo;noisier&rdquo; capture. As opposed to capturing the raw HDMI signal, we now have to deal with the real world and its irritating fluctuations in ambient light levels and all that the rest. I have no doubt it is *possible* to compensate for this (after all this is what the human eye/brain does all the time), but the question is how much work it will be. Can&rsquo;t speak for anyone else at Mozilla, but I&rsquo;m not sure if I really have the time to start a Ph.D-level research project in computational vision. ðŸ˜‰ I&rsquo;m optimistic that won&rsquo;t be necessary, but we&rsquo;ll just have to wait and see.</p> 
  <hr/>
</article>
<footer>
 <ul class="pagination">
  <li class="page-item"><a class="page-link" href="/tags/FirefoxOS.html">
    <quote>&larr;</quote></a></li>
  <li class="page-item"><a class="page-link" href="/tags/FirefoxOS.html">1</a></li>
  <li class="page-item active"><a class="page-link" href="/tags/FirefoxOS-2.html">2</a></li>
  <li class="page-item disabled"><a class="page-link" href="#">
    <quote>&rarr;</quote></a></li></ul></footer>
    </div>
    <footer class="container max-w-screen-md px-8 py-4 mx-auto less-important">
      <p>Comments / thoughts? Feel free to send an email to wlach on protonmail.com.</p>
      <p>
        Site generated by
        <a href="https://github.com/greghendershott/frog">Frog</a>.
        Post content is licensed under a
        <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"
          >Creative Commons Attribution 4.0 Unported License</a
        >.
      </p>
    </footer>
  </body>
</html>