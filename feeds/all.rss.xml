<?xml version="1.0" encoding="utf-8"?> 
<rss version="2.0">
 <channel>
  <title>William Lachance's Log: William Lachance's Log</title>
  <description>William Lachance's Log: William Lachance's Log</description>
  <link>https://wlach.github.io/index.html</link>
  <lastBuildDate>Thu, 26 Oct 2017 20:58:20 UT</lastBuildDate>
  <pubDate>Thu, 26 Oct 2017 20:58:20 UT</pubDate>
  <ttl>1800</ttl>
  <item>
   <title>Better or worse: by what measure?</title>
   <link>https://wlach.github.io/blog/2017/10/better-or-worse-by-what-measure/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-10-better-or-worse-by-what-measure</guid>
   <pubDate>Thu, 26 Oct 2017 20:58:20 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Ok, after a series of posts extolling the virtues of my current project, it&amp;rsquo;s time to take a more critical look at some of its current limitations, and what we might do about them. In my &lt;a href="/blog/2017/10/mission-control/"&gt;introductory post&lt;/a&gt;, I talked about how Mission Control can let us know how &amp;ldquo;crashy&amp;rdquo; a new release is, within a short interval of it being released. I also alluded to the fact that things appear considerably worse when something first goes out, though I didn&amp;rsquo;t go into a lot of detail about how and why that happens.&lt;/p&gt;

&lt;p&gt;It just so happens that a new point release (56.0.2) just went out, so it&amp;rsquo;s a perfect opportunity to revisit this issue. Let&amp;rsquo;s take a look at what the graphs are saying (each of the images is also a link to the dashboard where they were generated):&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=172740&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1508990400"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.0.2.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ZOMG! It looks like 56.0.2 is off the charts relative to the two previous releases (56.0 and 56.0.1). Is it time to sound the alarm? Mission control abort? Well, let&amp;rsquo;s see what happens the last time we rolled something new out, say 56.0.1:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=345540&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1507435200"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.0.1.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We see the exact same pattern. Hmm. How about 56.0?&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=431940&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1506398400"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yep, same pattern here too (actually slightly worse).&lt;/p&gt;

&lt;p&gt;What could be going on? Let&amp;rsquo;s start by reviewing what these time series graphs are based on. Each point on the graph represents the number of crashes reported by telemetry &amp;ldquo;main&amp;rdquo; pings corresponding to that channel/version/platform within a five minute interval, divided by the number of usage hours (how long users have had Firefox open) also reported in that interval. A main ping is submitted under &lt;a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html"&gt;a few circumstances&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;The user shuts down Firefox&lt;/li&gt;
 &lt;li&gt;It’s been about 24 hours since the last time we sent a main ping.&lt;/li&gt;
 &lt;li&gt;The user starts Firefox after Firefox failed to start properly&lt;/li&gt;
 &lt;li&gt;The user changes something about Firefox’s environment (adds an addon, flips a user preference)&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A high crash rate either means a larger number of crashes over the same number of usage hours, or a lower number of usage hours over the same number of crashes. There are several likely explanations for why we might see this type of crashy behaviour immediately after a new release:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;A Firefox update is applied after the user restarts their browser for any  reason, including their browser crash. Thus a user whose browser crashes a  lot (for any reason), is more prone to update to the latest version sooner  than a user that doesn’t crash as much.&lt;/li&gt;
 &lt;li&gt;Inherently, any crash data submitted to telemetry after a new version is  released will have a low number of usage hours attached, because the  client would not have had a chance to use it much (because it&amp;rsquo;s so new).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Assuming that we&amp;rsquo;re reasonably satisfied with the above explanation, there&amp;rsquo;s a few things we could try to do to correct for this situation when implementing an &amp;ldquo;alerting&amp;rdquo; system for mission control (the next item on my todo list for this project):&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Set &amp;ldquo;error&amp;rdquo; thresholds for each crash measure sufficiently high that  we don&amp;rsquo;t consider these high initial values an error (i.e. only alert  if there is are 500 crashes per 1k hours).&lt;/li&gt;
 &lt;li&gt;Only trigger an error threshold when some kind of minimum quantity of  usage hours has been observed (this has the disadvantage of potentially  obscuring a serious problem until a large percentage of the user population  is affected by it).&lt;/li&gt;
 &lt;li&gt;Come up with some expected range of what we expect a value to be for  when a new version of firefox is first released and ratchet  that down as time goes on (according to some kind of model of our previous expectations).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;The initial specification for this project called for just using raw thresholds for these measures (discounting usage hours), but I&amp;rsquo;m becoming increasingly convinced that won&amp;rsquo;t cut it. I&amp;rsquo;m not a quality control expert, but 500 crashes for 1k hours of use sounds completely unacceptable if we&amp;rsquo;re measuring things at all accurately (which I believe we are given a sufficient period of time). At the same time, generating 20&amp;ndash;30 “alerts” every time a new release went out wouldn’t particularly helpful either. Once again, we’re going to have to do this the hard way&amp;hellip;&lt;/p&gt;

&lt;p&gt;&amp;mdash;&lt;/p&gt;

&lt;p&gt;If this sounds interesting and you have some react/d3/data visualization skills (or would like to gain some), &lt;a href="/blog/2017/10/mission-control-ready-for-contributions/"&gt;learn about contributing to mission control&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Shout out to &lt;a href="https://chuttenblog.wordpress.com/"&gt;chutten&lt;/a&gt; for reviewing this post and providing feedback and additions.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Mission Control: Ready for contributions</title>
   <link>https://wlach.github.io/blog/2017/10/mission-control-ready-for-contributions/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-10-mission-control-ready-for-contributions</guid>
   <pubDate>Fri, 20 Oct 2017 18:33:19 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;One of the great design decisions that was made for &lt;a href="https://treeherder.mozilla.org"&gt;Treeherder&lt;/a&gt; was a strict seperation of the client and server portions of the codebase. While its backend was moderately complicated to get up and running (especially into a state that looked at all like what we were running in production), you could get its web frontend running (pointed against the production data) just by starting up a simple node.js server. This dramatically lowered the barrier to entry, for Mozilla employees and casual contributors alike.&lt;/p&gt;

&lt;p&gt;I knew right from the beginning that I wanted to take the same approach with &lt;a href="https://wlach.github.io/blog/2017/10/mission-control/"&gt;Mission Control&lt;/a&gt;. While the full source of the project is available, unfortunately it isn&amp;rsquo;t presently possible to bring up the full stack with real data, as that requires privileged access to the athena/parquet error aggregates table. But since the UI is self-contained, it&amp;rsquo;s quite easy to bring up a development environment that allows you to freely browse the cached data which is stored server-side (essentially: &lt;code&gt;git clone https://github.com/mozilla/missioncontrol.git &amp;amp;&amp;amp; yarn install &amp;amp;&amp;amp; yarn start&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;In my experience, the most interesting problems when it comes to projects like these center around the question of how to present extremely complex data in a way that is intuitive but not misleading. Probably 90% of that work happens in the frontend. In the past, I&amp;rsquo;ve had pretty good luck finding contributors for my projects (especially &lt;a href="/tags/Perfherder.html"&gt;Perfherder&lt;/a&gt;) by doing call-outs on this blog. So let it be known: If Mission Control sounds like an interesting project and you know &lt;a href="https://reactjs.org/"&gt;React&lt;/a&gt;/&lt;a href="http://redux.js.org/"&gt;Redux&lt;/a&gt;/&lt;a href="https://d3js.org/"&gt;D3&lt;/a&gt;/&lt;a href="https://www.metricsgraphicsjs.org/"&gt;MetricsGraphics&lt;/a&gt; (or want to learn), let&amp;rsquo;s work together!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve created some &lt;a href="https://github.com/mozilla/missioncontrol/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;good first bugs&lt;/a&gt; to tackle in the github issue tracker. From there, I have a galaxy of other work in mind to improve and enhance the usefulness of this project. Please get in touch with me (wlach) on &lt;a href="https://wiki.mozilla.org/IRC"&gt;irc.mozilla.org&lt;/a&gt; #missioncontrol if you want to discuss further.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Mission Control</title>
   <link>https://wlach.github.io/blog/2017/10/mission-control/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-10-mission-control</guid>
   <pubDate>Fri, 06 Oct 2017 19:05:37 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Time for an overdue post on the mission control project that I&amp;rsquo;ve been working on for the past few quarters, since I transitioned to the data platform team.&lt;/p&gt;

&lt;p&gt;One of the gaps in our data story when it comes to Firefox is being able to see how a new release is doing in the immediate hours after release. Tools like &lt;a href="https://crash-stats.mozilla.com/home/product/Firefox"&gt;crashstats&lt;/a&gt; and the &lt;a href="https://telemetry.mozilla.org/new-pipeline/evo.html"&gt;telemetry evolution dashboard&lt;/a&gt; are great, but it can take many hours (if not days) before you can reliably see that there is an issue in a metric that we care about (number of crashes, say). This is just too long &amp;mdash; such delays unnecessarily retard rolling out a release when it is safe (because there is a paranoia that there might be some lingering problem which we we&amp;rsquo;re waiting to see reported). And if, somehow, despite our abundant caution a problem &lt;em&gt;did&lt;/em&gt; slip through it would take us some time to recognize it and roll out a fix.&lt;/p&gt;

&lt;p&gt;Enter mission control. By hooking up a high-performance spark streaming job directly to our ingestion pipeline, we can now be able to detect within moments whether firefox is performing unacceptably within the field according to a particular measure.&lt;/p&gt;

&lt;p&gt;To make the volume of data manageable, we create a grouped data set with the raw count of the various measures (e.g. main crashes, content crashes, slow script dialog counts) along with each unique combination of dimensions (e.g. platform, channel, release).&lt;/p&gt;

&lt;p&gt;Of course, all this data is not so useful without a tool to visualize it, which is what I&amp;rsquo;ve been spending the majority of my time on. The idea is to be able to go from a top level description of what&amp;rsquo;s going on a particular channel (release for example) all the way down to a detailed view of how a measure has been performing over a time interval:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2017/10/missioncontrol-ui.png 2x" /&gt;&lt;/p&gt;

&lt;p&gt;This particular screenshot shows the volume of content crashes (sampled every 5 minutes) over the last 48 hours on windows release. You&amp;rsquo;ll note that the later version (56.0) seems to be much crashier than earlier versions (55.0.3) which would seem to be a problem except that the populations are not directly comparable (since the profile of a user still on an older version of Firefox is rather different from that of one who has already upgraded). This is one of the still unsolved problems of this project: finding a reliable, automatable baseline of what an &amp;ldquo;acceptable result&amp;rdquo; for any particular measure might be.&lt;/p&gt;

&lt;p&gt;Even still, the tool can still be useful for exploring a bunch of data quickly and it has been progressing rapidly over the last few weeks. And like almost everything Mozilla does, both the &lt;a href="https://github.com/mozilla/missioncontrol/"&gt;source&lt;/a&gt; and &lt;a href="https://data-missioncontrol.dev.mozaws.net/"&gt;dashboard&lt;/a&gt; are open to the public. I&amp;rsquo;m planning on flagging some easier bugs for newer contributors to work on in the next couple weeks, but in the meantime if you&amp;rsquo;re interested in this project and want to get involved, feel free to look us up on irc.mozilla.org #missioncontrol (I&amp;rsquo;m there as &amp;lsquo;wlach&amp;rsquo;).&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Functional is the future</title>
   <link>https://wlach.github.io/blog/2017/08/functional-is-the-future/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-08-functional-is-the-future</guid>
   <pubDate>Mon, 28 Aug 2017 21:02:21 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Just spent well over an hour tracking down a silly bug in my code. For the &lt;a href="https://github.com/mozilla/missioncontrol/"&gt;mission control&lt;/a&gt; project, I wrote this very simple API method that returns a cached data structure to our front end:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;measure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;channel_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;channel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;platform_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;platform&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;measure_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;measure&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;interval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;interval&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;channel_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;platform_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;measure_name&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseBadRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"All of channel, platform, measure required"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_measure_cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;platform_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channel_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;measure_name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseNotFound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Data not available for this measure combination"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;min_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseBadRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Interval must be specified in seconds (as an integer)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Return any build data in the interval&lt;/span&gt;
        &lt;span class="n"&gt;empty_buildids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;empty_buildids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# don&amp;#39;t bother returning empty indexed data&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;empty_buildid&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;empty_buildids&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;empty_buildid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;JsonResponse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;measure_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, it takes 3 required parameters (channel, platform, and measure) and one optional one (interval), picks out the required data structure, filters it a bit, and returns it. This is &lt;em&gt;almost&lt;/em&gt; what we wanted for the frontend, unfortunately the time zone information isn&amp;rsquo;t quite what we want, since the strings that are returned don&amp;rsquo;t tell the frontend that they&amp;rsquo;re in UTC format &amp;mdash; they need a &amp;lsquo;Z&amp;rsquo; appended to them for that.&lt;/p&gt;

&lt;p&gt;After a bit of digging, I found out that Django&amp;rsquo;s &lt;a href="https://github.com/django/django/blob/afc06b56256f78ab832ff8066ac6f34b7443de22/django/core/serializers/json.py#L76"&gt;json serializer&lt;/a&gt; will only add the Z if the tzinfo structure is specified. So I figured out a simple pattern for adding that (using the dateutil library, which we are fortunately already using):&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dateutil.tz&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tzutc&lt;/span&gt;
&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mydatestamp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;I tested this quickly on the python console and it seemed to work great. But when I added the code to my function, the unit tests mysteriously failed. Can you see why?&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# add utc timezone info to each date, so django will serialize a&lt;/span&gt;
    &lt;span class="c1"&gt;# &amp;#39;Z&amp;#39; to the end of the string (and so javascript&amp;#39;s date constructor&lt;/span&gt;
    &lt;span class="c1"&gt;# will know it&amp;#39;s utc)&lt;/span&gt;
    &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Trick question: there&amp;rsquo;s actually nothing wrong with this code. But if you look at the block in context (see the top of the post), you see that it&amp;rsquo;s only executed if &lt;em&gt;interval&lt;/em&gt; is specified, which it isn&amp;rsquo;t necessarily. The first case that my unit tests executed didn&amp;rsquo;t specify interval, so fail they did. It wasn&amp;rsquo;t immediately obvious to me why this was happening, so I went on a wild-goose chase of trying to figure out how the Django context might have been responsible for the unexpected output, before realizing my basic logic error.&lt;/p&gt;

&lt;p&gt;This was fairly easily corrected (my updated code applies the datetime-mapping unconditionally to set of optionally-filtered results) but perfectly illustrates my issue with idiomatic python: while the language itself has constructs like &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; that support the functional programming model, the language strongly steers you towards writing things in an imperative style that makes costly and annoying mistakes like this much easier to make. Yes, list and dictionary comprehensions are nice and compact but they start to break down in the more complex cases.&lt;/p&gt;

&lt;p&gt;As an experiment, I wrote up what this function might look like in a pure functional style with immutable data structures:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transform_and_filter_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;new_build_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;new_build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;new_build_data&lt;/span&gt;
&lt;span class="n"&gt;transformed_build_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;transform_and_filter_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;A work of art it isn&amp;rsquo;t &amp;mdash; and definitely not &amp;ldquo;pythonic&amp;rdquo;. Compare this to a similar piece of code written in Javascript (ES6) with lodash (using a hypothetical &lt;code&gt;tzified&lt;/code&gt; function):&lt;/p&gt;

&lt;div class="brush: js"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;transformedBuildData&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapValues&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;minTimestamp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;tzcified&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])].&lt;/span&gt;&lt;span class="nx"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;slice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="p"&gt;})),&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;buildId&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;A little bit easier to understand, but more importantly (to me anyway) it comes across as idiomatic and natural in a way that the python version just doesn&amp;rsquo;t. I&amp;rsquo;ve been happily programming Python for the last 10 years, but it&amp;rsquo;s increasingly feeling time to move on to greener pastures.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>mozregression's new mascot</title>
   <link>https://wlach.github.io/blog/2017/07/mozregression-s-new-mascot/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-07-mozregression-s-new-mascot</guid>
   <pubDate>Mon, 31 Jul 2017 15:32:02 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Spent a few hours this morning on a few housekeeping issues with &lt;a href="https://mozilla.github.io/mozregression"&gt;mozregression&lt;/a&gt;. The web site was badly in need of an update (it was full of references to obsolete stuff like B2G and codefirefox.com) and the usual pile of fixes motivated a new release of the actual software. But most importantly, mozregression now has a proper application icon / logo, thanks to Victoria Wang!&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/07/mozregressionicon3.png" /&gt;&lt;/p&gt;

&lt;p&gt;One of the nice parts about working at Mozilla is the flexibility it offers to just hack on stuff that&amp;rsquo;s important, whether or not it&amp;rsquo;s part of your formal job description. Maintaining mozregression is pretty far outside my current set of responsibilities (or even interests), but I keep it going because it&amp;rsquo;s a key tool used by developers team here and no one else seems willing to take it over. Fortunately, tools like appveyor and pypi keep the time suckage to a mostly-reasonable level.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Taking over an npm package: sanity prevails</title>
   <link>https://wlach.github.io/blog/2017/07/taking-over-an-npm-package-sanity-prevails/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-07-taking-over-an-npm-package-sanity-prevails</guid>
   <pubDate>Thu, 13 Jul 2017 15:08:40 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Sometimes problems are easier to solve than expected.&lt;/p&gt;

&lt;p&gt;For the last few months I&amp;rsquo;ve been working on the front end of a new project called &lt;a href="https://github.com/mozilla/missioncontrol"&gt;Mission Control&lt;/a&gt;, which aims to chart lots of interesting live information in something approximating realtime. Since this is a greenfield project, I thought it would make sense to use the currently-invogue framework at Mozilla (react) along with our standard visualization library, &lt;a href="http://metricsgraphicsjs.org/"&gt;metricsgraphics&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Metricsgraphics is great, but its jquery-esque api is somewhat at odds with the react way. The obvious solution to this problem is to wrap its functionality in a react component, and a quick google search determined that several people have tried to do exactly that, the most popular one being one called (obviously) react-metrics-graphics. Unfortunately, it hadn&amp;rsquo;t been updated in quite some time and some pull requests (including ones implementing features I needed for my project) weren&amp;rsquo;t being responded to.&lt;/p&gt;

&lt;p&gt;I expected this to be pretty difficult to resolve: I had no interaction with the author (Carter Feldman) before but based on my past experiences in free software, I was expecting stonewalling, leaving me no choice but to fork the package and give it a new name, a rather unsatisfying end result.&lt;/p&gt;

&lt;p&gt;But, hey, let&amp;rsquo;s keep an open mind on this. What does google say about unmaintained npm packages? Oh what&amp;rsquo;s this? They actually have a &lt;a href="https://docs.npmjs.com/misc/disputes"&gt;policy&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;tl;dr: You email the maintainer (politely) and CC support@npmjs.org about your interest in helping maintain the software. If you&amp;rsquo;re unable to come up with a resolution on your own, they will intervene.&lt;/p&gt;

&lt;p&gt;So I tried that. It turns out that Carter was really happy to hear that Mozilla was interested in taking over maintenance of this project, and not only gave me permission to start publishing newer versions to npm, but even transferred his repository over to Mozilla (so we could preserve issue and PR history). The project&amp;rsquo;s new location is here:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/mozilla/react-metrics-graphics"&gt;https://github.com/mozilla/react-metrics-graphics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In hindsight, this is obviously the most reasonable outcome and I&amp;rsquo;m not sure why I was expecting anything else. Is the node community just friendlier than other areas I&amp;rsquo;ve worked in? Have community standards improved generally? In any case, thank you Carter for a great piece of software, hopefully it will thrive in its new home. :P&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>The vastness</title>
   <link>https://wlach.github.io/blog/2017/07/the-vastness/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-07-the-vastness</guid>
   <pubDate>Sat, 08 Jul 2017 14:25:33 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Had a good all hands with the rest of Mozilla in San Francisco (at least those able and willing to attend due to the current political situation in the U.S.). I stayed a few extra days to hang out with some of my friends who had moved to S.F. On Sunday we went to Muir Woods, where I took this picture:&lt;/p&gt;

&lt;p&gt;&lt;a href="/files/2017/07/muirwoods-20170702.jpg"&gt;&lt;img style="width:640px" src="/files/2017/07/muirwoods-20170702.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It occurred to me at the time that I took that photo that pretty much every sensory receptor in my optic nerve was registering the signal of some kind of life. Thousands of beings (trees, clover, moss, lichens) in turn made up of trillions upon trillions of tiny beings (cells, bacteria) all conscious and interacting with each other in ways that I can barely begin to understand.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Using Docker to run automated tests</title>
   <link>https://wlach.github.io/blog/2017/06/using-docker-to-run-automated-tests/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-06-using-docker-to-run-automated-tests</guid>
   <pubDate>Fri, 02 Jun 2017 20:04:38 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;A couple months ago, I joined the Mozilla Data Platform team, to work on our &lt;a href="https://wiki.mozilla.org/Telemetry"&gt;Telemetry&lt;/a&gt; and automated data collection services. This has been an interesting transition for me, and a natural jumping off point from my work on &lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder"&gt;Perfherder&lt;/a&gt;. Now, instead of manipulating mere 10s of gigabytes worth of fairly regular data, I&amp;rsquo;m working with 100s of terrabytes of noisy data with a much larger number of dimensions. :P It&amp;rsquo;s been interesting so far.&lt;/p&gt;

&lt;p&gt;One of the first things I decided to work on was improving our unit testing story around a few of our primary packages for data analysis/etl: &lt;a href="https://github.com/mozilla/python_moztelemetry/"&gt;python_moztelemetry&lt;/a&gt; (a library we use for running custom spark jobs against Telemetry data) and &lt;a href="https://github.com/mozilla/telemetry-batch-view/"&gt;telemetry-batch-view&lt;/a&gt; (a set of scala jobs we run against the main telemetry data store to create a useful set of aggregations that are easily queried with tools like &lt;a href="https://redash.io/"&gt;redash&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;It turns out that these tools interact with several larger / more involved pieces than I&amp;rsquo;m used to dealing with (such as hbase and thrift). For continuous integration/automation, we already had a set of travis scripts to install and reproduce the environment needed to test these parts, but there was no straightforward way to do this locally. My third time through creating an Ubuntu virtual machine environment to reproduce this environment locally (long story), I figured it was finally time for me to investigate using something to automate that setup procedure and make it easier for new developers to get into these projects.&lt;/p&gt;

&lt;p&gt;I hadn&amp;rsquo;t used it much before, but &lt;a href="https://docker.com"&gt;Docker&lt;/a&gt; seemed like a fairly obvious choice. Small, simple, and Linuxy? Sign me up.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m pretty happy with how things turned out, but there were a few caveats. Docker is more of a general purpose tool for building environments for running &lt;em&gt;things&lt;/em&gt;, whether that be an apache webserver or a jabber messaging doohickey (whereas e.g. something like travis is basically a domain-specific language for creating and running automated tests). There were a few tricks I needed to employ to make the whole testing process smooth in both cases, which I&amp;rsquo;ll document here for posterity:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;You can &lt;code&gt;ADD&lt;/code&gt; a set of files / directories to a docker environment inside your Dockerfile, but if you want your set of tests to pick up any changes made since the environment was created, you really should mount your testing directory inside the container using the &lt;code&gt;-v&lt;/code&gt; option.&lt;/li&gt;
 &lt;li&gt;If you need to download/install a piece of software when building the docker container, use the &lt;code&gt;RUN&lt;/code&gt; directive instead of &lt;code&gt;ADD&lt;/code&gt;. This will speed up rebuilding the container while you&amp;rsquo;re iterating on it (because you can take advantage of the Docker layers cache).&lt;/li&gt;
 &lt;li&gt;You almost certainly want to create a script (&lt;a href="https://github.com/mozilla/python_moztelemetry/blob/d2aa84bbac09465d38eeb0b5beb20edc7ddcc21b/runtests.sh"&gt;example&lt;/a&gt;) to streamline all the steps of running the tests: this will make running the tests easier for anyone wanting to contribute to your project and reduce the amount of documentation that you will have to write.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;The relevant files and documentation are in the repositories linked above.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Easier reproduction of intermittent test failures in automation</title>
   <link>https://wlach.github.io/blog/2017/04/easier-reproduction-of-intermittent-test-failures-in-automation/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-04-easier-reproduction-of-intermittent-test-failures-in-automation</guid>
   <pubDate>Wed, 05 Apr 2017 20:14:35 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;As part of the &lt;a href="https://wiki.mozilla.org/Auto-tools/Projects/Stockwell"&gt;Stockwell project&lt;/a&gt;, I&amp;rsquo;ve been hacking on ways to make it easier for developers to diagnose failure of our tests in automation. It&amp;rsquo;s often very difficult to reproduce an intermittent failure we see in Treeherder locally since the environment is so different, but historically it has been a big hassle to get access to the machines we use in automation for various reasons.&lt;/p&gt;

&lt;p&gt;One option that rolled out last year was the so-called one-click loaner, which enabled developers to sign out an virtual machine instance identical to the ones used to run unit tests (at least if the tests are running on Taskcluster, which is increasingly often the case), then execute their particular case with whatever extra debugging options they would find useful. This is a big step forward, but it&amp;rsquo;s still quite a bit of hassle, since it requires a bunch of manual work on the part of the developer to interact with the instance.&lt;/p&gt;

&lt;p&gt;What if we could &lt;em&gt;just&lt;/em&gt; re-run the particular test an arbitrary number of times with whatever options we wanted, simply by clicking on a few buttons on Treeherder? I&amp;rsquo;ve been exploring this for the first few months of 2017 and I&amp;rsquo;ve come up with a prototype which I think is ready for people to start playing with.&lt;/p&gt;

&lt;p&gt;The user interface to this is pretty straightforward. Just find a job you want to retrigger in Treeherder:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-selected-mochitest.png" /&gt;&lt;/p&gt;

&lt;p&gt;Then select the &amp;rsquo;&amp;hellip;&amp;rsquo; option in the panel below and press &amp;ldquo;Custom Action&amp;hellip;&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-taskcluster-options.png" /&gt;&lt;/p&gt;

&lt;p&gt;You should get a small piece of JSON to edit, which corresponds to the configuration for the retriggered job:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-custom-action.png" /&gt;&lt;/p&gt;

&lt;p&gt;The main field to edit is &amp;ldquo;path&amp;rdquo;. You should set this to the name of the test you want to try retriggering. For example &lt;code&gt;dom/animation/test/css-transitions/test_animation-ready.html&lt;/code&gt;. You can also set custom Firefox preferences and environment variables, to turn on different types of debugging.&lt;/p&gt;

&lt;p&gt;Unfortunately as usual with a new feature at Mozilla, there are a bunch of limitations and caveats:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;This depends on functionality that&amp;rsquo;s only in Taskcluster, so  buildbot jobs are exempt.&lt;/li&gt;
 &lt;li&gt;No support for Android yet. In combination with the above  limitation, this implies that this functionality only works  on Linux (at least until other platforms are moved to Taskcluster,  which hopefully isn&amp;rsquo;t that far off).&lt;/li&gt;
 &lt;li&gt;Browser chrome tests failing in mysterious ways if run repeatedly  (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1347654"&gt;bug 1347654&lt;/a&gt;)&lt;/li&gt;
 &lt;li&gt;Only reftest and mochitest are currently supported. XPCShell  support is blocked by the lack of support in its harness for  running a job repeatedly (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1347696"&gt;bug 1347696&lt;/a&gt;).  Web Platform Tests need the requisite support in mozharness for  just setting up the tests without running them &amp;mdash; the same issue  that prevents us from debugging such tests with a one-click loaner  (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1348833"&gt;bug 1348833&lt;/a&gt;).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Aside from fixing the above limitations, the following features would also be really nifty to have:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Ability to trigger a custom job as part of a try push (i.e.  not needing to retrigger off an existing job)&lt;/li&gt;
 &lt;li&gt;Run these jobs under rr, and provide a way to login and  interactively debug when the problem is actually reproduced.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;I am actually in the process of moving to another team @ Mozilla (more on that in another post), so I probably won&amp;rsquo;t have a ton of time to work on the above &amp;mdash; but I&amp;rsquo;d be happy to help anyone who&amp;rsquo;s interested in developing this idea further.&lt;/p&gt;

&lt;p&gt;A special shout out to the &lt;a href="https://wiki.mozilla.org/TaskCluster"&gt;Taskcluster&lt;/a&gt; team for helping me with the development of this feature: in particular the action task implementation from &lt;a href="https://jonasfj.dk/"&gt;Jonas Finnemann Jensen&lt;/a&gt; that made it possible to develop this feature in the first place.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Cancel all the things</title>
   <link>https://wlach.github.io/blog/2017/02/cancel-all-the-things/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2017-02-cancel-all-the-things</guid>
   <pubDate>Tue, 07 Feb 2017 18:36:09 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;I just added a feature to Treeherder which lets you cancel a set of jobs (say, from a botched try push) much more easily. I&amp;rsquo;m hopeful that this will be helpful in keeping our resource usage on try more under control.&lt;/p&gt;

&lt;p&gt;It uses the &amp;ldquo;pinboard&amp;rdquo; feature of Treeherder which very few people are familiar with, so I made a very short video tutorial on how to make use of this feature and put it on the Joy of Automation channel:&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/ryzsy38yw5A" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;

&lt;p&gt;Happy cancelling!&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Training an autoclassifier</title>
   <link>https://wlach.github.io/blog/2016/11/training-an-autoclassifier/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-11-training-an-autoclassifier</guid>
   <pubDate>Mon, 28 Nov 2016 21:29:47 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Here at Mozilla, we&amp;rsquo;ve accepted that a certain amount of intermittent failure in our automated testing of Firefox is to be expected. That is, for every push, a subset of the tests that we run will fail for reasons that have nothing to do with the quality (or lack thereof) of the push itself.&lt;/p&gt;

&lt;p&gt;On the main integration branches that developers commit code to, we have dedicated staff and volunteers called sheriffs who attempt to distinguish these expected failures from intermittents through a manual classification process using &lt;a href="https://treeherder.mozilla.org"&gt;Treeherder&lt;/a&gt;. On any given push, you can usually find some failed jobs that have stars beside them, this is the work of the sheriffs, indicating that a job&amp;rsquo;s failure is &amp;ldquo;nothing to worry about&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/11/treeherder-in-action.png" /&gt;&lt;/p&gt;

&lt;p&gt;This generally works pretty well, though unfortunately it doesn&amp;rsquo;t help developers who need to test their changes on Try, which have the same sorts of failures but no sheriffs to watch them or interpret the results. For this reason (and a few others which I won&amp;rsquo;t go into detail on here), there&amp;rsquo;s been much interest in having Treeherder autoclassify known failures.&lt;/p&gt;

&lt;p&gt;We have a partially implemented version that attempts to do this based on structured (failure line) information, but we&amp;rsquo;ve had some difficulty creating a reasonable user interface to train it. Sheriffs are used to being able to quickly tag many jobs with the same bug. Having to go through each job&amp;rsquo;s failure lines and manually annotate each of them is much more time consuming, at least with the approaches that have been tried so far.&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/11/treeherder-per-line-classification.png" /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s quite possible that this is a solvable problem, but I thought it might be an interesting exercise to see how far we could get training an autoclassifier with only the existing per-job classifications as training data. With some recent work I&amp;rsquo;ve done on refactoring Treeherder&amp;rsquo;s database, getting a complete set of per-job failure line information is only a small SQL query away:&lt;/p&gt;

&lt;div class="brush: sql"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bug_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;bug_job_map&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;
  &lt;span class="k"&gt;left&lt;/span&gt; &lt;span class="k"&gt;join&lt;/span&gt; &lt;span class="n"&gt;text_log_step&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;job_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;job_id&lt;/span&gt;
  &lt;span class="k"&gt;left&lt;/span&gt; &lt;span class="k"&gt;join&lt;/span&gt; &lt;span class="n"&gt;text_log_error&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;
  &lt;span class="k"&gt;where&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;created&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2016-10-31&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;created&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2016-11-24&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bug_id&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;
  &lt;span class="k"&gt;order&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Just to give some explanation of this query, the &amp;ldquo;bug_job_map&amp;rdquo; provides a list of bugs that have been applied to jobs. The &amp;ldquo;text_log_step&amp;rdquo; and &amp;ldquo;text_log_error&amp;rdquo; tables contain the actual errors that Treeherder has extracted from the textual logs (to explain the failure). From this raw list of mappings and errors, we can construct a data structure incorporating the job, the assigned bug and the textual errors inside it. For example:&lt;/p&gt;

&lt;div class="brush: json"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="nt"&gt;"bug_number"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1202623&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="nt"&gt;"lines"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Found a tab after previous test timed out: http:/&amp;lt;number&amp;gt;&amp;lt;number&amp;gt;:&amp;lt;number&amp;gt;/browser/browser/base/content/test/plugins/plugin_test.html -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js A promise chain failed to handle a rejection:  - at chrome://mochikit/content/browser-test.js:&amp;lt;number&amp;gt; - TypeError: this.SimpleTest.isExpectingUncaughtException is not a function"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window&lt;/span&gt;
&lt;span class="s2"&gt;  after previous test timed out -"&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Some quick google searching revealed that &lt;a href="http://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; is a popular tool for experimenting with text classifications. They even had a &lt;a href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"&gt;tutorial&lt;/a&gt; on classifying newsgroup posts which seemed tantalizingly close to what we needed to do here. In that example, they wanted to predict which newsgroup a post belonged to based on its content. In our case, we want to predict which existing bug a job failure should belong to based on its error lines.&lt;/p&gt;

&lt;p&gt;There are obviously some differences in our domain: test failures are much more regular and structured. There are lots of numbers in them which are mostly irrelevant to the classification (e.g. the &amp;ldquo;expected 12 pixels different, got 10!&amp;rdquo; type errors in reftests). Ordering of failures might matter. Still, some of the techniques used on corpora of normal text documents for training a classifier probably map nicely onto what we&amp;rsquo;re trying to do here: it seems plausible that weighting words which occur more frequently less strongly against ones that are less common would be helpful, for example, and that&amp;rsquo;s one thing their default transformers does.&lt;/p&gt;

&lt;p&gt;In any case, I built up a small little script to download a subset of the downloaded data (from November 1st to November 23rd), used it as training data for a classifier, then tested that against another subset of test failures between November 24th and 28th.&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_files&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfTransformer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SGDClassifier&lt;/span&gt;


&lt;span class="n"&gt;training_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_files&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;training&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;count_vect&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X_train_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_vect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfTransformer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X_train_tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train_counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SGDClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hinge&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;penalty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;l2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train_tfidf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;num_missed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;walk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;testing/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;bugnum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;bugnum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fname&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fname&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; (skipping, empty)"&lt;/span&gt;
            &lt;span class="n"&gt;X_new_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_vect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;X_new_tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_new_counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target_names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_new_tfidf&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;bugnum&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; correct"&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_missed&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; missed (&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;)"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"Correct: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; Missed: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; Ratio: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_correct&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_missed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;num_missed&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;With absolutely no tweaking whatsoever, I got an accuracy rate of 75% on the test data. That is, the algorithm chose the correct classification given the failure text 1312 times out of 1959. Not bad for a first attempt!&lt;/p&gt;

&lt;p&gt;After getting that working, I did some initial testing to see if I could get better results by reusing some of the error ETL summary code in Treeherder we use for bug suggestions, but the results were pretty much the same.&lt;/p&gt;

&lt;p&gt;So what&amp;rsquo;s next? This seems like a wide open area to me, but some initial areas that seem worth exploring, if we wanted to take this idea further:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;Investigate cases where the autoclassification failed or had a near miss. Is there a pattern here? Is there something simple we could do, either by tweaking the input data or using a better vectorizer/tokenizer?&lt;/li&gt;
 &lt;li&gt;Have a confidence threshold for using the autoclassifier&amp;rsquo;s data. It seems likely to me that many of the cases above where we got the wrong were cases where the classifier itself wasn&amp;rsquo;t that confident in the result (vs. others). We can either present that in the user interface or avoid classifications for these cases altogether (and leave it up to a human being to make a decision on whether this is an intermittent).&lt;/li&gt;
 &lt;li&gt;Using the structured log data inside the database as input to a classifier. Structured log data here is much more regular and denser than the free text that we&amp;rsquo;re using. Even if it isn&amp;rsquo;t explicitly classified, we may well get better results by using it as our input data.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;If you&amp;rsquo;d like to experiment with the data and/or code, I&amp;rsquo;ve put it up on a &lt;a href="https://github.com/wlach/treeherder-classifier"&gt;github repository&lt;/a&gt;.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Slow Treeherder, Fast Treeherder</title>
   <link>https://wlach.github.io/blog/2016/10/slow-treeherder-fast-treeherder/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-10-slow-treeherder-fast-treeherder</guid>
   <pubDate>Mon, 31 Oct 2016 15:40:00 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Just wanted to talk about some recent performance improvements we&amp;rsquo;ve made recently to &lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Treeherder"&gt;Treeherder&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1311511"&gt;Bug 1311511&lt;/a&gt;: Changed the repository endpoint so we don&amp;rsquo;t do 40 redundant database  queries (this was generally innocuous, but could delay loading by  400ms if the database was under heavy load).&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1310016"&gt;Bug 1310016&lt;/a&gt;: Persisted database connections across requests (this  can save ~40&amp;ndash;50ms per request, of which there can be 5&amp;ndash;10  when loading a Treeherder page).&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1308782"&gt;Bug 1308782&lt;/a&gt;: &lt;em&gt;Don&amp;rsquo;t&lt;/em&gt; download job type and group information  from the server to get a &amp;ldquo;sorting order&amp;rdquo; for the job lists. This was  never necessary, but it&amp;rsquo;s gotten exponentially more painful as  people have added job types to Treeherder (job type information is  now around a megabyte of JSON these days). This saves 5&amp;ndash;10 seconds on a  typical page load.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;There&amp;rsquo;s more to come, but with these changes Treeherder should be faster for everyone to load. It should be particularly noticeable on try pushes, where the last item was by far the largest bottleneck. Here&amp;rsquo;s a youtube video of the changes:&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/xNJGoZhA4Vs" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;

&lt;p&gt;The original is on the left. The newer, faster Treeherder is on the right. Pay particular attention to how much faster the job information populates.&lt;/p&gt;

&lt;p&gt;Moral of the story? Optimization can be helpful, but it&amp;rsquo;s better if you can avoid doing the work altogether.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Herding Automation Infrastructure</title>
   <link>https://wlach.github.io/blog/2016/08/herding-automation-infrastructure/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-08-herding-automation-infrastructure</guid>
   <pubDate>Wed, 17 Aug 2016 20:18:12 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;For every commit to Firefox, we run a battery of builds and automated tests on the resulting source tree to make sure that the result still works and meets our correctness and performance quality criteria. This is expensive: every new push to our repository implies hundreds of hours of machine time. However, automated quality control is essential to ensure that the product that we&amp;rsquo;re shipping to users is something that we can be proud of.&lt;/p&gt;

&lt;p&gt;But what about evaluating the quality of the product which does the building and testing? Who does that? And by what criteria would we say that our automation system is good or bad? Up to now, our procedures for this have been rather embarassingly adhoc. With some exceptions (such as &lt;a href="https://brasstacks.mozilla.com/orangefactor/"&gt;OrangeFactor&lt;/a&gt;), our QA process amounts to motivated engineers doing a one-off analysis of a particular piece of the system, filing a few bugs, then forgetting about it. Occasionally someone will propose turning build and test automation for a specific platform on or off in mozilla.dev.planning.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d like to suggest that the time has come to take a more systemic approach to this class of problem. We spend a lot of money on people and machines to maintain this infrastructure, and I think we need a more disciplined approach to make sure that we are getting good value for that investment.&lt;/p&gt;

&lt;p&gt;As a starting point, I feel like we need to pay closer attention to the following characteristics of our automation:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;End-to-end times from push submission to full completion of all  build and test jobs: if this gets too long, it makes the lives  of all sorts of people painful &amp;mdash; tree closures become longer when  they happen (because it takes longer to either notice bustage or  find out that it&amp;rsquo;s fixed), developers have to wait longer for  try pushes (making them more likely to just push directly to an  integration branch, causing the former problem&amp;hellip;)&lt;/li&gt;
 &lt;li&gt;Number of machine hours consumed by the different types of test  jobs: our resources are large (relatively speaking), but not  unlimited. We need proper accounting of where we&amp;rsquo;re spending money  and time. In some cases, resources used to perform a task that  we don&amp;rsquo;t care that much about could be redeployed towards an  underresourced task that we do care about. A good example of this  was linux32 talos (performance tests) last year: when the question  was raised of why we were doing performance testing on this specific  platform (in addition to Linux64), no one could come up with a great  justification. So we turned the tests off and reconfigured the machines  to do Windows performance tests (where we were suffering from a severe  lack of capacity).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Over the past week, I&amp;rsquo;ve been prototyping a project I&amp;rsquo;ve been calling &amp;ldquo;Infraherder&amp;rdquo; which uses the data inside &lt;a href="https://treeherder.mozilla.org"&gt;Treeherder&lt;/a&gt;&amp;rsquo;s job database to try to answer these questions (and maybe some others that I haven&amp;rsquo;t thought of yet). You can see a hacky version of it on &lt;a href="http://wlach.github.io/treeherder/ui/infra.html#/last-finished"&gt;my github fork&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Why implement this in Treeherder you might ask? Two reasons. First, Treeherder already stores the job data in a historical archive that&amp;rsquo;s easy to query (using SQL). Using this directly makes sense over creating a new data store. Second, Treeherder provides a useful set of front-end components with which to build a UI with which to visualize this information. I actually did my initial prototyping inside an ipython notebook, but it quickly became obvious that for my results to be useful to others at Mozilla we needed some kind of real dashboard that people could dig into.&lt;/p&gt;

&lt;p&gt;On the Treeherder team at Mozilla, we&amp;rsquo;ve found the &lt;a href="https://newrelic.com"&gt;New Relic&lt;/a&gt; software to be invaluable for diagnosing and fixing quality and performance problems for Treeherder itself, so I took some inspiration from it (unfortunately the problem space of our automation is not quite the same as that of a web application, so we can&amp;rsquo;t just use New Relic directly).&lt;/p&gt;

&lt;p&gt;There are currently two views in the prototype, a &amp;ldquo;last finished&amp;rdquo; view and a &amp;ldquo;total&amp;rdquo; view. I&amp;rsquo;ll describe each of them in turn.&lt;/p&gt;

&lt;h3 id="last-finished"&gt;Last finished&lt;/h3&gt;

&lt;p&gt;This view shows the counts of which scheduled automation jobs were the &amp;ldquo;last&amp;rdquo; to finish. The hypothesis is that jobs that are frequently last indicate blockers to developer productivity, as they are the &amp;ldquo;long pole&amp;rdquo; in being able to determine if a push is good or bad.&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/08/infraherder-last-finished.png" width="500px" /&gt;&lt;/p&gt;

&lt;p&gt;Right away from this view, you can see the mochitest devtools 9 test is often the last to finish on try, with Windows 7 mochitest debug a close second. Assuming that the reasons for this are not resource starvation (they don&amp;rsquo;t appear to be), we could probably get results into the hands of developers and sheriffs faster if we split these jobs into two seperate ones. I filed bugs &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1294489"&gt;1294489&lt;/a&gt; and &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1294706"&gt;1294706&lt;/a&gt; to address these issues.&lt;/p&gt;

&lt;h3 id="total-time"&gt;Total Time&lt;/h3&gt;

&lt;p&gt;This view just shows which jobs are taking up the most machine hours.&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/08/infraherder-total.png" width="500px" /&gt;&lt;/p&gt;

&lt;p&gt;Probably unsurprisingly, it seems like it&amp;rsquo;s Android test jobs that are taking up most of the time here: these tests are running on multiple layers of emulation (AWS instances to emulate Linux hardware, then the already slow QEMU-based Android simulator) so are not expected to have fast runtime. I wonder if it might not be worth considering running these tests on faster instances and/or bare metal machines.&lt;/p&gt;

&lt;p&gt;Linux32 debug tests seem to be another large consumer of resources. Market conditions make turning these tests off altogether a non-starter (see bug &lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1255890"&gt;1255890&lt;/a&gt;), but how much value do we really derive from running the debug version of linux32 through automation (given that we&amp;rsquo;re already doing the same for 64-bit Linux)?&lt;/p&gt;

&lt;h3 id="request-for-comments"&gt;Request for comments&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve created &lt;a href="https://docs.google.com/document/d/1SrlJQQ3qWuM0tvruG6Lr59t3hJ4XRUoMIrIRQYvwu9A/edit?usp=sharing"&gt;an RFC&lt;/a&gt; for this project on Google Docs, as a sort of test case for a new process we&amp;rsquo;re thinking of using in Engineering Productivity for these sorts of projects. If you have any questions or comments, I&amp;rsquo;d love to hear them! My perspective on this vast problem space is limited, so I&amp;rsquo;m sure there are things that I&amp;rsquo;m missing.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Perfherder Quarter of Contribution Summer 2016: Results</title>
   <link>https://wlach.github.io/blog/2016/08/perfherder-quarter-of-contribution-summer-2016-results/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-08-perfherder-quarter-of-contribution-summer-2016-results</guid>
   <pubDate>Wed, 10 Aug 2016 20:37:05 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Following on the footsteps of Mike Ling&amp;rsquo;s &lt;a href="/blog/2015/09/perfherder-summer-of-contribution-thoughts/"&gt;amazing work&lt;/a&gt; on &lt;a href="https://wiki.mozilla.org/ngineeringProductivity‎/Projects/Perfherder"&gt;Perfherder&lt;/a&gt; in 2015 (he&amp;rsquo;s gone on to do a GSOC project), I got two amazing contributors to continue working on the project for a few weeks this summer as part of our &lt;a href="https://wiki.mozilla.org/Auto-tools/New_Contributor/Quarter_of_Contribution"&gt;quarter of contribution&lt;/a&gt; program: Shruti Jasoria and Roy Chiang.&lt;/p&gt;

&lt;p&gt;Shruti started by adding a feature to the treeherder/perfherder backend (ability to enable or disable a new performance framework on a tentative basis), then went on to make all sorts of improvements to the Treeherder / Perfherder frontend, fixing bugs in the performance sheriffing frontend, updating code to use more modern standards (including a gigantic patch to enable a bunch of eslint rules and fix the corresponding problems).&lt;/p&gt;

&lt;p&gt;Roy worked all over the codebase, starting with some simple frontend fixes to Treeherder, moving on to fix a large number of nits in Perfherder&amp;rsquo;s alerts view. My personal favorite is the fact that we now paginate the list of alerts inside this view, which makes navigation waaaaay back into history possible:&lt;/p&gt;

&lt;p&gt;&lt;a href="/files/2016/08/perfherder-alert-pagination.png"&gt;&lt;img src="/files/2016/08/perfherder-alert-pagination.png" alt="alert pagination" width="300px" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can see a summary of their work at these links:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://github.com/mozilla/treeherder/commits/master?author=SJasoria"&gt;Shruti Jasoria&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://github.com/mozilla/treeherder/commits/master?author=crosscent"&gt;Roy Chiang&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Thank you Shruti and Roy! You&amp;rsquo;ve helped to make sure Firefox (and Servo!) performance remains top-notch.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Quarter of Contribution: June / July 2016 edition</title>
   <link>https://wlach.github.io/blog/2016/05/quarter-of-contribution-june-july-2016-edition/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-05-quarter-of-contribution-june-july-2016-edition</guid>
   <pubDate>Fri, 27 May 2016 14:51:54 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Just wanted to announce that, once again, my team (&lt;a href="https://wiki.mozilla.org/EngineeringProductivity"&gt;Mozilla Engineering Productivity&lt;/a&gt;) is just about to start running another &lt;a href="https://wiki.mozilla.org/Auto-tools/New_Contributor/Quarter_of_Contribution"&gt;quarter of contribution&lt;/a&gt; &amp;mdash; a great opportunity for newer community members to dive deep on some of the projects we&amp;rsquo;re working on, brush up on their programming and problem solving skills, and work with experienced mentors. You can find more information on this program &lt;a href="https://wiki.mozilla.org/Auto-tools/New_Contributor/Quarter_of_Contribution/Summer_2016"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve found this program to be a really great experience on both sides &amp;mdash; it&amp;rsquo;s an opportunity for contributors to really go beyond the &amp;ldquo;good first bug&amp;rdquo; style of patches to having a really substantial impact on some of the projects that we&amp;rsquo;re working on while gaining lots of software development skills that are useful in the real world.&lt;/p&gt;

&lt;p&gt;Once again, I&amp;rsquo;m going to be mentoring one or two people on the Perfherder project, a tool we use to measure and sheriff Firefox performance. If you&amp;rsquo;re inclined to work on some really interesting data analysis and user interface problems in Python and JavaScript, please have a look at the &lt;a href="https://wiki.mozilla.org/Auto-tools/New_Contributor/Quarter_of_Contribution/Perfherder"&gt;project page&lt;/a&gt; and get in touch. :)&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Are We Fast Yet and Perfherder</title>
   <link>https://wlach.github.io/blog/2016/03/are-we-fast-yet-and-perfherder/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-03-are-we-fast-yet-and-perfherder</guid>
   <pubDate>Wed, 30 Mar 2016 15:42:39 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;Historically at Mozilla, we&amp;rsquo;ve had a bunch of different systems running to benchmark Firefox&amp;rsquo;s performance. The two most broadly-scoped are &lt;a href="https://wiki.mozilla.org/Buildbot/Talos"&gt;Talos&lt;/a&gt; (which runs as part of our build process, and emphasizes common real-world use cases, like page loading) and &lt;a href="https://arewefastyet.com/"&gt;Are We Fast Yet&lt;/a&gt; (which runs seperately, and emphasizes JavaScript performance and benchmarks).&lt;/p&gt;

&lt;p&gt;As many of you know, most of my focus over the last year-and-a-bit has been developing a system called Perfherder, which aims to make monitoring and acting on performance data easier. A great introduction to Perfherder is my &lt;a href="/blog/2016/03/platform-engineering-project-of-the-month-perfherder/"&gt;project of the month post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The initial focus of Perfherder has been Talos, which is deeply integrated into our automation and also maintained by Engineering Productivity (my group). However, the intention was always to allow anyone in the Mozilla community to submit performance data for Firefox and sheriff it, much like Treeherder has supported the submission of test result data from third parties (e.g. autophone, Firefox UI tests). There are more commonalities than differences in how we do performance sheriffing with Are We Fast Yet (which currently has its own web interface) and Perfherder, so it made sense to see if we could pool resources.&lt;/p&gt;

&lt;p&gt;So, over the last couple of months, &lt;a href="https://elvis314.wordpress.com/"&gt;Joel Maher&lt;/a&gt; and I have been in discussions with Hannes Verschore, current maintainer of Are We Fast Yet (AWFY) to see what could be done. It looks like it is possible for Perfherder to provide most of what AWFY needs, though there are a few exceptions. I thought for the benefit of others, it might be useful to outline what&amp;rsquo;s done, what&amp;rsquo;s coming next, and what might not be implemented (at least not any time soon).&lt;/p&gt;

&lt;h3 id="whats-done"&gt;What&amp;rsquo;s done&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Get AWFY submitting data to Perfherder and allow it to be sheriffed  seperately from Talos. This is working on treeherder stage, and you  can already examine the &lt;a href="https://treeherder.allizom.org/perf.html#/alerts?status=0&amp;amp;framework=5"&gt;alert data&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="whats-in-progress-or-in-the-near-term-pipeline"&gt;What&amp;rsquo;s in progress (or in the near-term pipeline)&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Allow custom alerting behaviour (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1254595"&gt;bug 1254595&lt;/a&gt;). For example, we want  to alert on subtests for AWFY while still summarizing the results.  This is something we don&amp;rsquo;t currently support.&lt;/li&gt;
 &lt;li&gt;Allow creating an alert manually (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1260791"&gt;bug 1260791&lt;/a&gt;). Sadly, our regression detection  algorithm is not perfect. AWFY already supports this, we should too. This is something we also want for Talos.&lt;/li&gt;
 &lt;li&gt;Make regression-filing templates non-talos-specific (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1260805"&gt;bug 1260805&lt;/a&gt;). Currently we have a convenience template for filing bugs for performance  regressions, but this is currently specific to various things about Talos (job running instructions, links to documentation, etc.). We should  make it configurable so other projects like AWFY can take advantage of this functionality.&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="under-consideration"&gt;Under consideration&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Some kind of support for bisecting a push to figure out which patch  caused a regression. AWFY currently supports this, but it&amp;rsquo;s a fairly  difficult thing to add to Perfherder (much of which is built upon  Treeherder&amp;rsquo;s per-push result model). Maybe this is something we should  do, but it would be a significant amount of effort.&lt;/li&gt;
 &lt;li&gt;Proprietary benchmarks: AWFY runs one benchmark the results for  which we can&amp;rsquo;t make public. Adding &amp;ldquo;private&amp;rdquo; jobs or results to  Treeherder is likely a big can of worms, but it might be something  we want to do eventually.&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="probably-wont-fix"&gt;Probably won&amp;rsquo;t fix&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Supporting comparative measurements between Firefox and other  browsers. This is an important task, but doesn&amp;rsquo;t really fit into the  model of Perfherder, which is intimately tied to the revision data  associated with Firefox. To do this would require detailed tracking  of Chrome on the same basis, and I don&amp;rsquo;t think that&amp;rsquo;s really a place  where we want to go. We should definitely monitor for general  trends, but I think that is best done with a seperate system.&lt;/li&gt;&lt;/ul&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Platform engineering project of the month: Perfherder</title>
   <link>https://wlach.github.io/blog/2016/03/platform-engineering-project-of-the-month-perfherder/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-03-platform-engineering-project-of-the-month-perfherder</guid>
   <pubDate>Tue, 15 Mar 2016 00:10:57 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;&lt;em&gt;[ originally posted on &lt;a href="https://groups.google.com/d/msg/mozilla.dev.platform/itdfru6csSk/vfVP_WDXBgAJ"&gt;mozilla.dev.platform&lt;/a&gt; ]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Hello from Platform Engineering Operations! Once a month we highlight one of our projects to help the Mozilla community discover a useful tool or an interesting contribution opportunity.&lt;/p&gt;

&lt;p&gt;This month’s project is Perfherder!&lt;/p&gt;

&lt;h3 id="what-is-perfherder"&gt;What is Perfherder?&lt;/h3&gt;

&lt;p&gt;Perfherder is a generic system for visualizing and analyzing performance data produced by the many automated tests we run here at Mozilla (such as Talos, &amp;ldquo;Are we fast yet?&amp;rdquo; or &amp;ldquo;Are we slim yet?&amp;rdquo;). The chief goal of the project is to make sure that performance of Firefox gets better, not worse over time. It does this by:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Tracking the performance generated by our automated tests, allowing  them to be visualized on a graph.&lt;/li&gt;
 &lt;li&gt;Providing a sheriffing dashboard which allows for incoming  alerts of performance regressions to be annotated and triaged - bugs  can be filed based on a template and their resolution status can be  tracked.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;In addition to its own user interface, Perfherder also provides an API on the backend that other people can use to build custom performance visualizations and dashboards. For example, the metrics group has been working on a set of release quality indices for performance based on Perfherder data:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://metrics.mozilla.com/quality-indices/"&gt;https://metrics.mozilla.com/quality-indices/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="how-it-works"&gt;How it works&lt;/h3&gt;

&lt;p&gt;Perfherder is part of Treeherder, building on that project&amp;rsquo;s existing support for tracking revision and test job information. Like the rest of Treeherder, Perfherder&amp;rsquo;s backend is written in Python, using the Django web framework. The user interface is written as an AngularJS application.&lt;/p&gt;

&lt;h3 id="learning-more"&gt;Learning more&lt;/h3&gt;

&lt;p&gt;For more information on Perfherder than you ever wanted to know, please see the wiki page:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder"&gt;https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder&lt;/a&gt;&lt;/p&gt;

&lt;h3 id="can-i-contribute"&gt;Can I contribute?&lt;/h3&gt;

&lt;p&gt;Yes! We have had some fantastic contributions from the community to Perfherder, and are always looking for more. This is a great way to help developers make Firefox faster (or use less memory). The core of Perfherder is relatively small, so this is a great chance to learn either Django or Angular if you have a small amount of Python and/or JavaScript experience.&lt;/p&gt;

&lt;p&gt;We have set aside a set of bugs that are suitable for getting started here:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://bugzilla.mozilla.org/buglist.cgi?list_id=12722722&amp;amp;resolution=---&amp;amp;status_whiteboard_type=allwordssubstr&amp;amp;query_format=advanced&amp;amp;status_whiteboard=perfherder-starter-bug"&gt;https://bugzilla.mozilla.org/buglist.cgi?list_id=12722722&amp;amp;resolution=---&amp;amp;status_whiteboard_type=allwordssubstr&amp;amp;query_format=advanced&amp;amp;status_whiteboard=perfherder-starter-bug&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For more information on contributing to Perfherder, please see the contribution section of the above wiki page:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder#Contribution"&gt;https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder#Contribution&lt;/a&gt;&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Talos suites now visible from trychooser</title>
   <link>https://wlach.github.io/blog/2016/02/talos-suites-now-visible-from-trychooser/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-02-talos-suites-now-visible-from-trychooser</guid>
   <pubDate>Sat, 13 Feb 2016 19:28:47 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;It&amp;rsquo;s a small thing, but I submitted a patch to &lt;a href="http://trychooser.pub.build.mozilla.org/"&gt;trychooser&lt;/a&gt; last week which adds a tooltip indicating the actual Talos tests that are run as part of the various jobs that you can schedule as part of a try push. It&amp;rsquo;s in production as of now:&lt;/p&gt;

&lt;video src="/files/2016/02/talos-trychooser.webm" controls="controls" autoplay="autoplay"&gt;&lt;/video&gt;

&lt;p&gt;Previously, the only way to do this was to dig into the actual buildbot code, which was more than a little annoying.&lt;/p&gt;

&lt;p&gt;If you think your patch might have a good chance of regressing performance, please do run the &lt;a href="https://wiki.mozilla.org/Buildbot/Talos/Tests"&gt;Talos tests&lt;/a&gt; before you check in. It&amp;rsquo;s much less work for all of us when these things are caught before integration and back outs are no fun for anyone. We really need better documentation for this stuff, but meanwhile if you need help with this, please ask in the #perf channel on irc.mozilla.org&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>Albert Low</title>
   <link>https://wlach.github.io/blog/2016/02/albert-low/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-02-albert-low</guid>
   <pubDate>Sun, 07 Feb 2016 21:45:41 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;I was saddened to find out last week that the person who introduced me to Zen practice three years ago, Albert Low, has passed away. Albert was the teacher of the &lt;a href="http://www.zenmontreal.ca/"&gt;Montreal Zen Center&lt;/a&gt;, which I was a member of for a brief period (6 months) in 2014 before I moved to Toronto and started practicing at &lt;a href="http://torontozen.org/"&gt;the center&lt;/a&gt; here.&lt;/p&gt;

&lt;p&gt;Albert&amp;rsquo;s instruction was the gateway to a practice that has had a profound impact on my life. More than anything, he helped me understand Zen as something that one could incorporate directly into daily life. I will remain forever grateful.&lt;/p&gt;&lt;/html&gt;</description></item>
  <item>
   <title>NIXI is moving too</title>
   <link>https://wlach.github.io/blog/2016/01/nixi-is-moving-too/?utm_source=all&amp;utm_medium=RSS</link>
   <guid>urn:https-wlach-github-io:-blog-2016-01-nixi-is-moving-too</guid>
   <pubDate>Sat, 09 Jan 2016 04:21:13 UT</pubDate>
   <description>&lt;html&gt;
&lt;p&gt;As my blog goes to github pages, so do my other side projects. I just moved nixi, my bikestation finder project, to github pages. Its new location:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://wlach.github.io/nixi"&gt;http://wlach.github.io/nixi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I opted not to move over the domain: it would have cost extra money, time and hassle and I couldn&amp;rsquo;t justify it for the very, very small number of people that still use this site (yes, there are a few, including myself!). For now, nixi.ca will redirect to the github pages site until I decommision my linode server, probably at the end of January (end of Feburary at the latest).&lt;/p&gt;

&lt;p&gt;This transition brings some other changes with it:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Now using the &lt;a href="https://citybik.es"&gt;citybik.es&lt;/a&gt; API directly,  instead of proxing through an intermediary server. This was necessitated  by the switch to github pages, but I suspect this will be more reliable  than what we were doing before. Thanks citybik.es!&lt;/li&gt;
 &lt;li&gt;Removed all analytics and facebook integration. As with the domain, it didn&amp;rsquo;t  seem worth bringing over. Also, it&amp;rsquo;s nice to give people at least marginally  more privacy than they had before where possible.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;I still think nixi is worlds more usable than most bikesharing maps, even if it&amp;rsquo;s not an actively maintained project of mine any more. Here&amp;rsquo;s hoping it lasts many more years in its new incarnation.&lt;/p&gt;&lt;/html&gt;</description></item></channel></rss>