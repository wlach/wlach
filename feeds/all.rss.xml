<?xml version="1.0" encoding="utf-8"?> 
<rss version="2.0">
 <channel>
  <title>William Lachance's Log: William Lachance's Log</title>
  <description>William Lachance's Log: William Lachance's Log</description>
  <link>https://wlach.github.io/index.html</link>
  <lastBuildDate>Tue, 05 Jun 2018 21:50:32 UT</lastBuildDate>
  <pubDate>Tue, 05 Jun 2018 21:50:32 UT</pubDate>
  <ttl>1800</ttl>
  <item>
   <title>Mission Control 1.0</title>
   <link>https://wlach.github.io/blog/2018/06/mission-control-1-0?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-06-mission-control-1-0</guid>
   <pubDate>Tue, 05 Jun 2018 21:50:32 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Just a quick announcement that the first &amp;ldquo;production-ready&amp;rdquo; version of Mission Control just went live yesterday, at this easy-to-remember URL:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://missioncontrol.telemetry.mozilla.org"&gt;https://missioncontrol.telemetry.mozilla.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For those not yet familiar with the project, Mission Control aims to track release stability and quality across Firefox releases. It is similar in spirit to arewestableyet and other crash dashboards, with the following new and exciting properties:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Uses the full set of crash counts gathered via telemetry, rather than the arbitrary  sample that users decide to submit to crash-stats&lt;/li&gt;
 &lt;li&gt;Results are available within minutes of ingestion by telemetry (although be warned  &lt;a href="/blog/2017/10/better-or-worse-by-what-measure/"&gt;initial results for a release always look bad&lt;/a&gt;)&lt;/li&gt;
 &lt;li&gt;The denominator in our crash rate is usage hours, rather than the probably-incorrect  calculation of active-daily-installs used by  &lt;a href="https://arewestableyet.com"&gt;arewestableyet&lt;/a&gt; (not a knock on the people who  wrote that tool, there was nothing better available at the time)&lt;/li&gt;
 &lt;li&gt;We have a detailed breakdown of the results by platform (rather than letting Windows  results dominate the overall rates due to its high volume of usage)&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;In general, my hope is that this tool will provide a more scientific and accurate idea of release stability and quality over time. There&amp;rsquo;s lots more to do, but I think this is a promising start. Much gratitude to &lt;a href="https://home.kairo.at/blog/2014-04/how_effective_is_the_stability_program"&gt;kairo&lt;/a&gt;, calixte, &lt;a href="https://chuttenblog.wordpress.com/"&gt;chutten&lt;/a&gt; and others who helped build my understanding of this area.&lt;/p&gt;

&lt;p&gt;The dashboard itself an easier thing to show than talk about, so I recorded a quick demonstration of some of the dashboard&amp;rsquo;s capabilities and published it on air mozilla:&lt;/p&gt;

&lt;iframe src="https://air.mozilla.org/mission-control-dashboard-intro/video/" width="896" height="524" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href="https://air.mozilla.org/mission-control-dashboard-intro/"&gt;link&lt;/a&gt;&lt;/p&gt;</description></item>
  <item>
   <title>Some thoughts on opinion polling in the Ontario 2018 election</title>
   <link>https://wlach.github.io/blog/2018/05/some-thoughts-on-opinion-polling-in-the-ontario-2018-election?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-05-some-thoughts-on-opinion-polling-in-the-ontario-2018-election</guid>
   <pubDate>Sun, 27 May 2018 16:57:30 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Like many, I&amp;rsquo;ve been a bit worried about the Ontario election, and have been rather obsessively checking a site called the &lt;a href="https://newsinteractives.cbc.ca/onvotes/poll-tracker/"&gt;Ontario Poll Tracker&lt;/a&gt;.&lt;/p&gt;

&lt;center&gt;&lt;img style="width:400px" srcset="/files/2018/05/CBC-poll-tracker-main.png 2x" /&gt;&lt;/center&gt;

&lt;p&gt;It has nice and shiny graphs and uses authoritative language and purports to provide a scientific analysis which predicts the election. Despite this, it&amp;rsquo;s my assertion that this kind of predictive modelling is nothing more than snake oil. I keep on reminding myself that I shouldn&amp;rsquo;t take it too seriously, but haven&amp;rsquo;t been too successful so far. This blog post is a reminder to myself on why I should stop reloading that site so much, but maybe it will be helpful to others as well. As a warning, it&amp;rsquo;s not going to say anything particularly novel. If you have any kind of background in statistics at all, this is probably going to be quite boring.&lt;/p&gt;

&lt;p&gt;First, a story. Way back when I had just graduated from university in 2003, I worked briefly at an &amp;ldquo;opinion research company&amp;rdquo;, telephoning people for various opinion surveys. It was easily the worst job I ever had, horrible for both the people doing the calling and those who were being called.&lt;/p&gt;

&lt;p&gt;The work was mind-numbingly repetitive. Get assigned a poll. Telephone people using an autodialer, work through the script using the DOS-based software the call center was using where they would answer multiple-choice questions. Repeat as many times as you can over the course of an hour. The topics were varied, but roughly 50/50 political parties doing private polling and businesses trying to get marketing data. In either case, the questions were definitely of the &amp;ldquo;lowest common denominator&amp;rdquo; type question (i.e. &amp;ldquo;Which products are you likely to buy in the next 12 months&amp;rdquo;, &amp;ldquo;If an election were held today, would you vote for party A, B, or C?&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;One of the few benefits of tedious jobs is that they give you time to think about things. In this case, one of my distinct experiential take aways as that the results that we were getting were incredibly unrepresentative.&lt;/p&gt;

&lt;p&gt;For a poll to be valid it is supposed to be &amp;ldquo;reasonably&amp;rdquo; reflective of the general population. Over the quantities that we&amp;rsquo;re talking about, that means anywhere from hundreds of thousands to millions of people. If we were able to truly randomly sample a small number from this group, the results are likely to be &amp;ldquo;representative of the whole&amp;rdquo; (within some confidence interval). Let&amp;rsquo;s write up a small python script to confirm this intuition:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 100,000 random numbers between 0 and 1&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;full_population_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;full_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;full_population_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="c1"&gt;# average over entire result&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;full_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;full_population_size&lt;/span&gt;
&lt;span class="mf"&gt;0.501036568906331&lt;/span&gt;

&lt;span class="c1"&gt;# pull out 100 randomly selected values from the full sample and&lt;/span&gt;
&lt;span class="c1"&gt;# get their average&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;random_subset_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;random_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;full_sample&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt;
                     &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset_size&lt;/span&gt;&lt;span class="p"&gt;)]]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;random_subset_size&lt;/span&gt;
&lt;span class="mf"&gt;0.4924555517866068&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Only a small fraction of the total population, but a result within 1% of the true value. Expressing it this way makes random sampling almost like a tautology. You probably learned this in high school. Great right?&lt;/p&gt;

&lt;p&gt;Unfortunately, real life always comes in to disturb these assumptions, as it always does. You see, there were all sorts of factors that would affect who we would be talking to and thus get datapoints from. At that time, most of the population still had a land-line telephone but there were a wealth of other factors that meant that we weren&amp;rsquo;t getting a truly randoms sample of data. Men (at least men under 60 or so) were much less likely to answer a telephone survey than women. For general opinion surveys, we were calling at a specific time of day when &lt;em&gt;most&lt;/em&gt; people were likely to be available &amp;mdash; but that certainly wouldn&amp;rsquo;t apply to everyone. Some people would work night shifts, etc., etc. In our example above, this would be like taking out half the results over (say) 0.75 from our sample &amp;mdash; the end result would tend to skew much lower than the true value.&lt;/p&gt;

&lt;p&gt;Just for fun, let&amp;rsquo;s try doing that and see how it affects the results:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# if we take away approximately half the results with a value of&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;gt;0.75, the population we are sampling from is reduced proportionally&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;full_sample&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;87607&lt;/span&gt;

&lt;span class="c1"&gt;# the sampled value is then proportionally skewed downwards (because&lt;/span&gt;
&lt;span class="c1"&gt;# a large percentage of the high values are no longer available)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;random_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt;
                     &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt;
                      &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
                    &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;random_subset_size&lt;/span&gt;
&lt;span class="mf"&gt;0.4585241853943395&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To try and get around this problem, the opinion polling company would try to demographically restrict who we were surveying past a certain point, so that the overall sample of the poll would reasonably reflect the characteristics of the population. This probably helped, but there&amp;rsquo;s only so much you can do here. For example, if you correct for the fact that men aged 20 to 60 are less likely to answer an opinion survey, your sample is going to now consist of those weird men who &lt;em&gt;do&lt;/em&gt; answer opinion surveys. Who knows what effect that&amp;rsquo;s going to have on your results?&lt;/p&gt;

&lt;p&gt;I want to be clear here: this is a methodological problem. Running more opinion polls doesn&amp;rsquo;t help. Probably some samples will be more affected by errors than others, but the problem remains regardless. Actually, let&amp;rsquo;s show this trivially for our small example:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;skewed_averages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;full_sample&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mf"&gt;0.75&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt;
                                         &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="n"&gt;random_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt;
          &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;full_sample_with_half75_removed&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt;
           &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset_size&lt;/span&gt;&lt;span class="p"&gt;)]]&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="n"&gt;skewed_averages&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_subset&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;skewed_averages&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.4585241853943395&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4271412530288919&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.46414511969024697&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4360740890986547&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="mf"&gt;0.4779021127791633&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.38419133106708714&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.48688298744651576&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.41076028280889915&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="mf"&gt;0.47975630795860363&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4381467970818846&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Each time we resampled from the main population and got a different result, but the end result was still one which was &lt;em&gt;far&lt;/em&gt; off from what we know in this case was the true value (0.5). Sampling from bad data doesn&amp;rsquo;t make up for these problems, it just gives you more bad results.&lt;/p&gt;

&lt;p&gt;Now, flash forward to 2018. Almost no one under 50 has a land-line anymore, people who have cell phones most often don&amp;rsquo;t answer to unknown callers. And don&amp;rsquo;t even get me started on how to find a representative set of people to participate in an &amp;ldquo;online panel&amp;rdquo;. What validity do polls have under these circumstances? I would say very little and probably more importantly we don&amp;rsquo;t even have a clear idea of &lt;em&gt;how&lt;/em&gt; our modern polls are skewed.&lt;/p&gt;

&lt;p&gt;There has been no shortage of thinking on how to correct for these problems but in my opinion it&amp;rsquo;s all just speculative and largely invalid. You can&amp;rsquo;t definitively solve the kind of uncertainty we&amp;rsquo;re talking about here by coming up with &amp;ldquo;just so&amp;rdquo; stories about how you&amp;rsquo;ve corrected for it. We might have some ideas about how our data is biased, but short of sampling the entire population and then seeing how our sampling method falls into that superset (which is impossible) there is no way of confirming that our efforts to correct for that bias were effective.&lt;/p&gt;

&lt;p&gt;With respect to the Ontario election which I alluded to above, the one thing that I am getting from the data is that support for the NDP (across the highly unrepresentative sample used in the polls) is increasing precipitously and that for the PC&amp;rsquo;s is decreasing almost as sharply. That seems to be a real phenomenon. We don&amp;rsquo;t know whether that crosses over to the general population but it doesn&amp;rsquo;t seem unreasonable to think it does. Exactly how is another question, and I make no assertions there.&lt;/p&gt;

&lt;center&gt;&lt;img style="width:400px" srcset="/files/2018/05/CBC-poll-tracker-trend.png 2x" /&gt;&lt;/center&gt;

&lt;p&gt;tl;dr If you don&amp;rsquo;t like the idea of &lt;a href="https://www.theguardian.com/world/2018/apr/30/doug-ford-ontario-conservative-trump-comparison-canada"&gt;Doug Ford&lt;/a&gt; in power, there is no reason to panic based on sites like the Ontario Poll Tracker. Spend your time doing something more productive, like convincing your friends and relatives to vote for someone who is not Conservative.&lt;/p&gt;</description></item>
  <item>
   <title>metricsgraphics movements</title>
   <link>https://wlach.github.io/blog/2018/04/metricsgraphics-movements?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-04-metricsgraphics-movements</guid>
   <pubDate>Mon, 30 Apr 2018 15:20:32 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Just wanted to give a quick update on some things that have been happening with the &lt;a href="https://www.metricsgraphics.org"&gt;metrics graphics&lt;/a&gt; since I stepped up to help with maintainership a few months ago:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://github.com/hamilton"&gt;Hamilton&lt;/a&gt;&amp;rsquo;s back as co-maintainer! This has been especially helpful  as he understands much of the historical context of metricsgraphics better than I do.&lt;/li&gt;
 &lt;li&gt;We&amp;rsquo;ve merged in a large number of small fixes and improvements into the codebase,  thanks to myself and a number of other contributors. Special shout-out to Thomas  Champagne, who has contributed a &lt;a href="https://github.com/metricsgraphics/metrics-graphics/commits?author=thomaschampagne"&gt;large number of nifty new features&lt;/a&gt;.&lt;/li&gt;
 &lt;li&gt;We moved the project from Mozilla to its &lt;a href="https://github.com/metricsgraphics/"&gt;own organization&lt;/a&gt; on  github. This feels like a much better way forward for a project which is supposed to be useful  far outside the bounds of Mozilla, and hopeful makes contributors feel more like the first-class  citizens of the project that they actually are.&lt;/li&gt;
 &lt;li&gt;We have a GSOC intern! As part of the Mozilla GSOC, Yunhao Zheng is going to be working on  adding rich brushing/zooming support to Metrics Graphics, which should be quite useful for  visualizing complex data in projects like &lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder"&gt;Perfherder&lt;/a&gt; (&lt;a href="https://docs.google.com/document/d/1_KIOJtemqlCBktDdfdjDuS4XhICeaKO3QhNRwbnnf-g/"&gt;Project outline&lt;/a&gt;, &lt;a href="https://summerofcode.withgoogle.com/projects/#5422620527296512"&gt;Yunhao&amp;rsquo;s proposal&lt;/a&gt;)&lt;/li&gt;&lt;/ul&gt;</description></item>
  <item>
   <title>Mission Control update</title>
   <link>https://wlach.github.io/blog/2018/04/mission-control-update?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-04-mission-control-update</guid>
   <pubDate>Fri, 06 Apr 2018 18:46:43 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Yep, still working on this project. We&amp;rsquo;ve shifted gears somewhat from trying to identify problems in a time series of error aggregates to tracking somewhat longer term trends release over release, to fill the needs of the release management team at Mozilla. It&amp;rsquo;s been a good change, I think. A bit of a tighter focus.&lt;/p&gt;

&lt;p&gt;The main motivator for this work is that the ADI (active daily install) numbers that crash stats used to provide as input to a similar service, &lt;a href="https://arewestableyet.com"&gt;AreWeStableYet&lt;/a&gt; (link requires Mozilla credentials), are going away and we need some kind of replacement. I&amp;rsquo;ve been learning about this older system worked (this &lt;a href="https://home.kairo.at/blog/2014-04/how_effective_is_the_stability_program"&gt;blog post&lt;/a&gt; from KaiRo was helpful) and trying to develop a replacement which reproduces some of its useful characteristics while also taking advantage of some of the new features that are provided by the &lt;a href="https://docs.telemetry.mozilla.org/datasets/streaming/error_aggregates/reference.html"&gt;error_aggregates&lt;/a&gt; dataset and the mission control user interface.&lt;/p&gt;

&lt;p&gt;Some preliminary screenshots of what I&amp;rsquo;ve been able to come up with:&lt;/p&gt;

&lt;center&gt;&lt;img style="width:400px" srcset="/files/2018/04/missioncontrol-main-view.png 2x" /&gt; &lt;img style="width:400px" srcset="/files/2018/04/missioncontrol-windows-release.png 2x" /&gt;&lt;/center&gt;

&lt;p&gt;One of the key things to keep in mind with this dashboard is that by default it shows an &lt;em&gt;adjusted&lt;/em&gt; set of rates (defined as total number of events divided by total usage khours), which means we compare the latest release to the previous one within the same time interval.&lt;/p&gt;

&lt;p&gt;So if, say, the latest release is &amp;ldquo;59&amp;rdquo; and it&amp;rsquo;s been out for two weeks, we will compare it against the previous release (&amp;ldquo;58&amp;rdquo;) in its first two weeks. As I&amp;rsquo;ve said here before, things are &lt;a href="/blog/2017/10/better-or-worse-by-what-measure"&gt;always crashier when they first go out&lt;/a&gt;, and comparing a new release to one that has been out in the field for some time is not a fair comparison at all.&lt;/p&gt;

&lt;p&gt;This adjusted view of things is still not apples-to-apples: the causality of crashes and errors is so complex that there will always be differences between releases which are beyond our control or even understanding. Many crash reports, for example, have nothing to do with our product but with third party software and web sites beyond our control. That said, I feel like this adjusted rate is still good enough to tell us (broadly speaking) (1) whether our latest release / beta / nightly is ok (i.e. there is no major showstopper issue) and (2) whether our overall error rate is going up or down over several versions (if there is a continual increase in our crash rate, it might point to a problem in our release/qa process).&lt;/p&gt;

&lt;p&gt;Interestingly, the first things that we&amp;rsquo;ve found with this system are not real problems with the product but data collection issues:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1447161"&gt;we don&amp;rsquo;t seem to be collecting counts of gmplugin crashes on Windows anymore via telemetry&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1413172#c8"&gt;the number of content_shutdown_crashes is greater than the number of content_crashes, even though the former is a superset of the latter&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Data issues aside, the indications are that there&amp;rsquo;s been a steady increase in the quality of Firefox over the last few releases based on the main user facing error metric we&amp;rsquo;ve cared about in the past (main crashes), so that&amp;rsquo;s good. :)&lt;/p&gt;

&lt;p&gt;If you want to play with the system yourself, the &lt;a href="https://data-missioncontrol.dev.mozaws.net/"&gt;development instance&lt;/a&gt; is still up. We will probably look at making this thing &amp;ldquo;official&amp;rdquo; next quarter.&lt;/p&gt;</description></item>
  <item>
   <title>Derived versus direct</title>
   <link>https://wlach.github.io/blog/2018/02/derived-versus-direct?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-02-derived-versus-direct</guid>
   <pubDate>Mon, 12 Feb 2018 21:06:40 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;To attempt to make complex phenomena more understandable, we often use derived measures when representing Telemetry data at Mozilla. For error rates for example, we often measure things in terms of &amp;ldquo;X per khours of use&amp;rdquo; (where X might be &amp;ldquo;main crashes&amp;rdquo;, &amp;ldquo;appearance of the slow script dialogue&amp;rdquo;). I.e. instead of showing a raw &lt;em&gt;count&lt;/em&gt; of errors we show a rate. Normally this is a good thing: it allows the user to easily compare two things which might have different raw numbers for whatever reason but where you&amp;rsquo;d normally expect the ratio to be similar. For example, we see that although the &lt;em&gt;uptake&lt;/em&gt; of the newly-released Firefox 58.0.2 is a bit slower than 58.0.1, the overall crash rate (as sampled every 5 minutes) is more or less the same after about a day has rolled around:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2018/02/main_crashes_normalized.png" /&gt;&lt;/p&gt;

&lt;p&gt;On the other hand, looking at raw counts doesn&amp;rsquo;t really give you much of a hint on how to interpret the results. Depending on the scale of the graph, the actual rates could actually resolve to being vastly different:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2018/02/main_crashes_raw.png" /&gt;&lt;/p&gt;

&lt;p&gt;Ok, so this simple tool (using a ratio) is useful. Yay! Unfortunately, there is one case where using this technique can lead to a very deceptive visualization: when the number of samples is really small, a few outliers can give a really false impression of what&amp;rsquo;s really happening. Take this graph of what the crash rate looked like &lt;em&gt;just after&lt;/em&gt; Firefox 58.0 was released:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2018/02/relative_small_crash_counts.png" /&gt;&lt;/p&gt;

&lt;p&gt;10 to 100 errors per 1000 hours, say it isn&amp;rsquo;t so? But wait, how many errors do we have absolutely? Hovering over a representative point in the graph with the normalization (use of a ratio) turned off:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2018/02/absolute_small_crash_counts.png" /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re really only talking about something between 1 to 40 crashes events over a relatively small number of usage hours. This is clearly so little data that we can&amp;rsquo;t (and shouldn&amp;rsquo;t) draw any kind of conclusion whatsoever.&lt;/p&gt;

&lt;p&gt;Ok, so that&amp;rsquo;s just science 101: don&amp;rsquo;t jump to conclusions based on small, vastly unrepresentative samples. Unfortunately due to human psychology people tend to assume that charts like this are authoritative and represent something real, absent an explanation otherwise &amp;mdash; and the use of a ratio obscured the one fact (extreme lack of data) that would have given the user a hint on how to correctly interpret the results. Something to keep in mind as we build our tools.&lt;/p&gt;</description></item>
  <item>
   <title>Giving and receiving help at Mozilla</title>
   <link>https://wlach.github.io/blog/2018/01/giving-and-receiving-help-at-mozilla?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-01-giving-and-receiving-help-at-mozilla</guid>
   <pubDate>Wed, 17 Jan 2018 18:49:34 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;This is going to sound corny, but helping people really is one of my favorite things at Mozilla, even with &lt;a href="https://mozilla.github.io/mozregression/"&gt;projects I have mostly moved on from&lt;/a&gt;. As someone who primarily works on internal tools, I love hearing about bugs in the software I maintain or questions on how to use it best.&lt;/p&gt;

&lt;p&gt;Given this, you might think that getting in touch with me via irc or slack is the fastest and best way to get your issue addressed. We certainly have a culture of using these instant-messaging applications at Mozilla for everything and anything. Unfortunately, I have found that being &amp;ldquo;always on&amp;rdquo; to respond to everything hasn&amp;rsquo;t been positive for either my productivity or mental health. My personal situation aside, getting pinged on irc while I&amp;rsquo;m out of the office often results in stuff getting lost &amp;mdash; the person who asked me the question is often gone by the time I return and am able to answer.&lt;/p&gt;

&lt;p&gt;With that in mind, here&amp;rsquo;s some notes on my preferred conversation style when making initial contact about an issue:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;Please don&amp;rsquo;t send context-free pings on irc. It has been &lt;a href="http://edunham.net/2017/10/05/saying_ping.html"&gt;explained elsewhere&lt;/a&gt;  why this doesn&amp;rsquo;t work that well, so I won&amp;rsquo;t repeat the argument here.&lt;/li&gt;
 &lt;li&gt;If you are at all suspicious that your issue might be a bug in some software  maintain, just &lt;a href="https://bugzilla.mozilla.org/enter_bug.cgi"&gt;file a bug&lt;/a&gt; and needinfo me. That puts us right on the path to documenting  the problem and getting to a resolution &amp;mdash; even if something turns out to not  be a bug, if you&amp;rsquo;re seeing an unexpected error it points to a usability issue.&lt;/li&gt;
 &lt;li&gt;For everything else, email is best. I do check it quite frequently between  bursts of work (i.e. many times a day). I promise I won&amp;rsquo;t leave you hanging  for days on end as long as I&amp;rsquo;m not on vacation.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;These aren&amp;rsquo;t ironclad rules. If your question pertains to a project I&amp;rsquo;m &lt;em&gt;actively&lt;/em&gt; working on, it might make sense to ping me on irc first (preferably on a channel where other people are around who might also be able to help). If it&amp;rsquo;s an actual &lt;em&gt;emergency&lt;/em&gt;, then of course talk to me on irc straight away (or even call me on my phone) &amp;mdash; if I don&amp;rsquo;t respond, then fall back to filing bug or sending email. Use common sense.&lt;/p&gt;

&lt;p&gt;One of my new years resolutions is to also apply these rules to my communications with others at Mozilla as well, so if you see my violating it feel free to point me back at this post. Or just use this handy meme I created:&lt;/p&gt;

&lt;center&gt;&lt;img src="/files/2018/01/scale-of-asking.jpg" /&gt;&lt;/center&gt;</description></item>
  <item>
   <title>Quitting Twitter</title>
   <link>https://wlach.github.io/blog/2018/01/quitting-twitter?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2018-01-quitting-twitter</guid>
   <pubDate>Sat, 13 Jan 2018 20:09:44 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;(this post probably won&amp;rsquo;t make much sense unless you have been a user of Twitter since/during 2016&amp;ndash;2018)&lt;/p&gt;

&lt;p&gt;Decided to kill my Twitter account today. Probably most people won&amp;rsquo;t miss my presence there as I haven&amp;rsquo;t actively posting on the site in quite some time, but I did check it quite frequently. I suspect it consumed (and I&amp;rsquo;m ashamed to admit this), at least an hour of my day on average. Twitter when I wake up, Twitter on the streetcar, Twitter every god damn empty moment.&lt;/p&gt;

&lt;p&gt;Of all the large social media propertes, I find Twitter by far leads in the amount of negative sentiment it displays, especially in the last year or so. Donald Trump, #GamerGate, Brexit, Nazis, the list goes on. That&amp;rsquo;s probably why it is so uniquely capable of grabbing my attention in particular, there&amp;rsquo;s some dark part of me which gravitates towards exactly this type of content.&lt;/p&gt;

&lt;p&gt;Now, due to the filter bubble effect, 99% of what &lt;em&gt;I&lt;/em&gt; see on that site is a negative &lt;em&gt;response&lt;/em&gt; to those things, but so what? The overwhelming of effect of my interaction with the site is simply to make me more more fearful and angry, nothing more. The very format of Twitter (brief bursts of performative text) doesn&amp;rsquo;t encourage any kind of intelligent or compassionate reaction to what you are seeing or reading. It would be one thing if the negative things I saw on Twitter motivated me to take a positive action of &lt;em&gt;any&lt;/em&gt; kind, but if the net effect of hearing bad news is just to make you feel bad, then what&amp;rsquo;s the point?&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not much of a fan of Facebook either, but it has (less often than I would like, but sometimes) been a platform for facilitating worthwhile social and cultural interactions both on the site and off. I could probably count the number of similar exchanges I have had on Twitter on one hand &amp;mdash; overwhelmingly my experience with twitter is that engagement (posting) leads only to a regrettable salvo of petty bickering and &lt;a href="http://tirania.org/blog/archive/2011/Feb-17.html"&gt;well actuallys&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, let&amp;rsquo;s see what life on the other side of this site is like. The demons which pulled me to Twitter every day are no doubt still there&amp;hellip; but hopefully they&amp;rsquo;ll be easier to handle without the influence of a technology which amplifies their effect.&lt;/p&gt;

&lt;p&gt;Further reading:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="http://www.macdrifter.com/2017/11/fuck-twitter.html"&gt;Fuck Twitter&lt;/a&gt;&lt;/li&gt;
 &lt;li&gt;&lt;a href="http://www.businessinsider.com/jaron-lanier-interview-on-silicon-valley-culture-metoo-backlash-ai-and-the-future-2017-12"&gt;Jaron Lanier&lt;/a&gt; on negative sentiment in social media (among other interesting topics)&lt;/li&gt;&lt;/ul&gt;</description></item>
  <item>
   <title>Maintaining metricsgraphics</title>
   <link>https://wlach.github.io/blog/2017/12/maintaining-metricsgraphics?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-12-maintaining-metricsgraphics</guid>
   <pubDate>Wed, 06 Dec 2017 22:16:23 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Just a quick announcement that I&amp;rsquo;ve taken it upon myself to assume some maintership duties of the popular &lt;a href="https://github.com/mozilla/metrics-graphics"&gt;MetricsGraphics&lt;/a&gt; library and have released a &lt;a href="https://www.npmjs.com/package/metrics-graphics"&gt;new version&lt;/a&gt; with some bug fixes (2.12.0). We use this package pretty extensively at Mozilla for visualizing telemetry and other time series data, but its original authors (Hamilton Ulmer and Ali Almossawi) have mostly moved on to other things so there was a bit of a gap in getting fixes and improvements in that I hope to fill.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t yet claim to be an expert in this library (which is quite rich and complex), but I&amp;rsquo;m sure I&amp;rsquo;ll learn more as I go along. At least initially, I expect that the changes I make will be small and primarily targetted to filling the needs of the &lt;a href="https://github.com/mozilla/missioncontrol"&gt;Mission Control&lt;/a&gt; project.&lt;/p&gt;

&lt;p&gt;Note that this emphatically does &lt;em&gt;not&lt;/em&gt; mean I am promising to respond to every issue/question/pull request made against the project. Like my work with mozregression and perfherder, my maintenance work is being done on a best-effort basis to support Mozilla and the larger open source community. I&amp;rsquo;ll help people out where I can, but there are only so many working hours in a day and I need to spend most of those pushing my team&amp;rsquo;s immediate projects and deliverables forward! In particular, when it comes to getting pull requests merged, small, self-contained and logical changes with good commit messages will take priority.&lt;/p&gt;</description></item>
  <item>
   <title>Better or worse: by what measure?</title>
   <link>https://wlach.github.io/blog/2017/10/better-or-worse-by-what-measure?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-10-better-or-worse-by-what-measure</guid>
   <pubDate>Thu, 26 Oct 2017 20:58:20 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Ok, after a series of posts extolling the virtues of my current project, it&amp;rsquo;s time to take a more critical look at some of its current limitations, and what we might do about them. In my &lt;a href="/blog/2017/10/mission-control/"&gt;introductory post&lt;/a&gt;, I talked about how Mission Control can let us know how &amp;ldquo;crashy&amp;rdquo; a new release is, within a short interval of it being released. I also alluded to the fact that things appear considerably worse when something first goes out, though I didn&amp;rsquo;t go into a lot of detail about how and why that happens.&lt;/p&gt;

&lt;p&gt;It just so happens that a new point release (56.0.2) just went out, so it&amp;rsquo;s a perfect opportunity to revisit this issue. Let&amp;rsquo;s take a look at what the graphs are saying (each of the images is also a link to the dashboard where they were generated):&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=172740&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1508990400"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.0.2.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ZOMG! It looks like 56.0.2 is off the charts relative to the two previous releases (56.0 and 56.0.1). Is it time to sound the alarm? Mission control abort? Well, let&amp;rsquo;s see what happens the last time we rolled something new out, say 56.0.1:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=345540&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1507435200"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.0.1.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We see the exact same pattern. Hmm. How about 56.0?&lt;/p&gt;

&lt;p&gt;&lt;a href="https://data-missioncontrol.dev.mozaws.net/#/release/windows/content_crashes?timeInterval=431940&amp;amp;percentile=99&amp;amp;normalized=1&amp;amp;disabledVersions=&amp;amp;versionGrouping=version&amp;amp;startTime=1506398400"&gt;&lt;img srcset="/files/2017/10/missioncontrol_windows_content_crashes_56.png 2x" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Yep, same pattern here too (actually slightly worse).&lt;/p&gt;

&lt;p&gt;What could be going on? Let&amp;rsquo;s start by reviewing what these time series graphs are based on. Each point on the graph represents the number of crashes reported by telemetry &amp;ldquo;main&amp;rdquo; pings corresponding to that channel/version/platform within a five minute interval, divided by the number of usage hours (how long users have had Firefox open) also reported in that interval. A main ping is submitted under &lt;a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html"&gt;a few circumstances&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;The user shuts down Firefox&lt;/li&gt;
 &lt;li&gt;It’s been about 24 hours since the last time we sent a main ping.&lt;/li&gt;
 &lt;li&gt;The user starts Firefox after Firefox failed to start properly&lt;/li&gt;
 &lt;li&gt;The user changes something about Firefox’s environment (adds an addon, flips a user preference)&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;A high crash rate either means a larger number of crashes over the same number of usage hours, or a lower number of usage hours over the same number of crashes. There are several likely explanations for why we might see this type of crashy behaviour immediately after a new release:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;A Firefox update is applied after the user restarts their browser for any  reason, including their browser crash. Thus a user whose browser crashes a  lot (for any reason), is more prone to update to the latest version sooner  than a user that doesn’t crash as much.&lt;/li&gt;
 &lt;li&gt;Inherently, any crash data submitted to telemetry after a new version is  released will have a low number of usage hours attached, because the  client would not have had a chance to use it much (because it&amp;rsquo;s so new).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Assuming that we&amp;rsquo;re reasonably satisfied with the above explanation, there&amp;rsquo;s a few things we could try to do to correct for this situation when implementing an &amp;ldquo;alerting&amp;rdquo; system for mission control (the next item on my todo list for this project):&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Set &amp;ldquo;error&amp;rdquo; thresholds for each crash measure sufficiently high that  we don&amp;rsquo;t consider these high initial values an error (i.e. only alert  if there is are 500 crashes per 1k hours).&lt;/li&gt;
 &lt;li&gt;Only trigger an error threshold when some kind of minimum quantity of  usage hours has been observed (this has the disadvantage of potentially  obscuring a serious problem until a large percentage of the user population  is affected by it).&lt;/li&gt;
 &lt;li&gt;Come up with some expected range of what we expect a value to be for  when a new version of firefox is first released and ratchet  that down as time goes on (according to some kind of model of our previous expectations).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;The initial specification for this project called for just using raw thresholds for these measures (discounting usage hours), but I&amp;rsquo;m becoming increasingly convinced that won&amp;rsquo;t cut it. I&amp;rsquo;m not a quality control expert, but 500 crashes for 1k hours of use sounds completely unacceptable if we&amp;rsquo;re measuring things at all accurately (which I believe we are given a sufficient period of time). At the same time, generating 20&amp;ndash;30 “alerts” every time a new release went out wouldn’t particularly helpful either. Once again, we’re going to have to do this the hard way&amp;hellip;&lt;/p&gt;

&lt;p&gt;&amp;mdash;&lt;/p&gt;

&lt;p&gt;If this sounds interesting and you have some react/d3/data visualization skills (or would like to gain some), &lt;a href="/blog/2017/10/mission-control-ready-for-contributions/"&gt;learn about contributing to mission control&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Shout out to &lt;a href="https://chuttenblog.wordpress.com/"&gt;chutten&lt;/a&gt; for reviewing this post and providing feedback and additions.&lt;/p&gt;</description></item>
  <item>
   <title>Mission Control: Ready for contributions</title>
   <link>https://wlach.github.io/blog/2017/10/mission-control-ready-for-contributions?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-10-mission-control-ready-for-contributions</guid>
   <pubDate>Fri, 20 Oct 2017 18:33:19 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;One of the great design decisions that was made for &lt;a href="https://treeherder.mozilla.org"&gt;Treeherder&lt;/a&gt; was a strict seperation of the client and server portions of the codebase. While its backend was moderately complicated to get up and running (especially into a state that looked at all like what we were running in production), you could get its web frontend running (pointed against the production data) just by starting up a simple node.js server. This dramatically lowered the barrier to entry, for Mozilla employees and casual contributors alike.&lt;/p&gt;

&lt;p&gt;I knew right from the beginning that I wanted to take the same approach with &lt;a href="https://wlach.github.io/blog/2017/10/mission-control/"&gt;Mission Control&lt;/a&gt;. While the full source of the project is available, unfortunately it isn&amp;rsquo;t presently possible to bring up the full stack with real data, as that requires privileged access to the athena/parquet error aggregates table. But since the UI is self-contained, it&amp;rsquo;s quite easy to bring up a development environment that allows you to freely browse the cached data which is stored server-side (essentially: &lt;code&gt;git clone https://github.com/mozilla/missioncontrol.git &amp;amp;&amp;amp; yarn install &amp;amp;&amp;amp; yarn start&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;In my experience, the most interesting problems when it comes to projects like these center around the question of how to present extremely complex data in a way that is intuitive but not misleading. Probably 90% of that work happens in the frontend. In the past, I&amp;rsquo;ve had pretty good luck finding contributors for my projects (especially &lt;a href="/tags/Perfherder.html"&gt;Perfherder&lt;/a&gt;) by doing call-outs on this blog. So let it be known: If Mission Control sounds like an interesting project and you know &lt;a href="https://reactjs.org/"&gt;React&lt;/a&gt;/&lt;a href="http://redux.js.org/"&gt;Redux&lt;/a&gt;/&lt;a href="https://d3js.org/"&gt;D3&lt;/a&gt;/&lt;a href="https://www.metricsgraphicsjs.org/"&gt;MetricsGraphics&lt;/a&gt; (or want to learn), let&amp;rsquo;s work together!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve created some &lt;a href="https://github.com/mozilla/missioncontrol/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;good first bugs&lt;/a&gt; to tackle in the github issue tracker. From there, I have a galaxy of other work in mind to improve and enhance the usefulness of this project. Please get in touch with me (wlach) on &lt;a href="https://wiki.mozilla.org/IRC"&gt;irc.mozilla.org&lt;/a&gt; #missioncontrol if you want to discuss further.&lt;/p&gt;</description></item>
  <item>
   <title>Mission Control</title>
   <link>https://wlach.github.io/blog/2017/10/mission-control?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-10-mission-control</guid>
   <pubDate>Fri, 06 Oct 2017 19:05:37 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Time for an overdue post on the mission control project that I&amp;rsquo;ve been working on for the past few quarters, since I transitioned to the data platform team.&lt;/p&gt;

&lt;p&gt;One of the gaps in our data story when it comes to Firefox is being able to see how a new release is doing in the immediate hours after release. Tools like &lt;a href="https://crash-stats.mozilla.com/home/product/Firefox"&gt;crashstats&lt;/a&gt; and the &lt;a href="https://telemetry.mozilla.org/new-pipeline/evo.html"&gt;telemetry evolution dashboard&lt;/a&gt; are great, but it can take many hours (if not days) before you can reliably see that there is an issue in a metric that we care about (number of crashes, say). This is just too long &amp;mdash; such delays unnecessarily retard rolling out a release when it is safe (because there is a paranoia that there might be some lingering problem which we we&amp;rsquo;re waiting to see reported). And if, somehow, despite our abundant caution a problem &lt;em&gt;did&lt;/em&gt; slip through it would take us some time to recognize it and roll out a fix.&lt;/p&gt;

&lt;p&gt;Enter mission control. By hooking up a high-performance spark streaming job directly to our ingestion pipeline, we can now be able to detect within moments whether firefox is performing unacceptably within the field according to a particular measure.&lt;/p&gt;

&lt;p&gt;To make the volume of data manageable, we create a grouped data set with the raw count of the various measures (e.g. main crashes, content crashes, slow script dialog counts) along with each unique combination of dimensions (e.g. platform, channel, release).&lt;/p&gt;

&lt;p&gt;Of course, all this data is not so useful without a tool to visualize it, which is what I&amp;rsquo;ve been spending the majority of my time on. The idea is to be able to go from a top level description of what&amp;rsquo;s going on a particular channel (release for example) all the way down to a detailed view of how a measure has been performing over a time interval:&lt;/p&gt;

&lt;p&gt;&lt;img srcset="/files/2017/10/missioncontrol-ui.png 2x" /&gt;&lt;/p&gt;

&lt;p&gt;This particular screenshot shows the volume of content crashes (sampled every 5 minutes) over the last 48 hours on windows release. You&amp;rsquo;ll note that the later version (56.0) seems to be much crashier than earlier versions (55.0.3) which would seem to be a problem except that the populations are not directly comparable (since the profile of a user still on an older version of Firefox is rather different from that of one who has already upgraded). This is one of the still unsolved problems of this project: finding a reliable, automatable baseline of what an &amp;ldquo;acceptable result&amp;rdquo; for any particular measure might be.&lt;/p&gt;

&lt;p&gt;Even still, the tool can still be useful for exploring a bunch of data quickly and it has been progressing rapidly over the last few weeks. And like almost everything Mozilla does, both the &lt;a href="https://github.com/mozilla/missioncontrol/"&gt;source&lt;/a&gt; and &lt;a href="https://data-missioncontrol.dev.mozaws.net/"&gt;dashboard&lt;/a&gt; are open to the public. I&amp;rsquo;m planning on flagging some easier bugs for newer contributors to work on in the next couple weeks, but in the meantime if you&amp;rsquo;re interested in this project and want to get involved, feel free to look us up on irc.mozilla.org #missioncontrol (I&amp;rsquo;m there as &amp;lsquo;wlach&amp;rsquo;).&lt;/p&gt;</description></item>
  <item>
   <title>Functional is the future</title>
   <link>https://wlach.github.io/blog/2017/08/functional-is-the-future?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-08-functional-is-the-future</guid>
   <pubDate>Mon, 28 Aug 2017 21:02:21 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Just spent well over an hour tracking down a silly bug in my code. For the &lt;a href="https://github.com/mozilla/missioncontrol/"&gt;mission control&lt;/a&gt; project, I wrote this very simple API method that returns a cached data structure to our front end:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;measure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;channel_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;channel&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;platform_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;platform&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;measure_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;measure&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;interval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;interval&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;channel_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;platform_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;measure_name&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseBadRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"All of channel, platform, measure required"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_measure_cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;platform_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channel_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;measure_name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseNotFound&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Data not available for this measure combination"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;min_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;HttpResponseBadRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Interval must be specified in seconds (as an integer)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Return any build data in the interval&lt;/span&gt;
        &lt;span class="n"&gt;empty_buildids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;empty_buildids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# don&amp;#39;t bother returning empty indexed data&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;empty_buildid&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;empty_buildids&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;empty_buildid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;JsonResponse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;measure_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, it takes 3 required parameters (channel, platform, and measure) and one optional one (interval), picks out the required data structure, filters it a bit, and returns it. This is &lt;em&gt;almost&lt;/em&gt; what we wanted for the frontend, unfortunately the time zone information isn&amp;rsquo;t quite what we want, since the strings that are returned don&amp;rsquo;t tell the frontend that they&amp;rsquo;re in UTC format &amp;mdash; they need a &amp;lsquo;Z&amp;rsquo; appended to them for that.&lt;/p&gt;

&lt;p&gt;After a bit of digging, I found out that Django&amp;rsquo;s &lt;a href="https://github.com/django/django/blob/afc06b56256f78ab832ff8066ac6f34b7443de22/django/core/serializers/json.py#L76"&gt;json serializer&lt;/a&gt; will only add the Z if the tzinfo structure is specified. So I figured out a simple pattern for adding that (using the dateutil library, which we are fortunately already using):&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dateutil.tz&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tzutc&lt;/span&gt;
&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mydatestamp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;I tested this quickly on the python console and it seemed to work great. But when I added the code to my function, the unit tests mysteriously failed. Can you see why?&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# add utc timezone info to each date, so django will serialize a&lt;/span&gt;
    &lt;span class="c1"&gt;# &amp;#39;Z&amp;#39; to the end of the string (and so javascript&amp;#39;s date constructor&lt;/span&gt;
    &lt;span class="c1"&gt;# will know it&amp;#39;s utc)&lt;/span&gt;
    &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Trick question: there&amp;rsquo;s actually nothing wrong with this code. But if you look at the block in context (see the top of the post), you see that it&amp;rsquo;s only executed if &lt;em&gt;interval&lt;/em&gt; is specified, which it isn&amp;rsquo;t necessarily. The first case that my unit tests executed didn&amp;rsquo;t specify interval, so fail they did. It wasn&amp;rsquo;t immediately obvious to me why this was happening, so I went on a wild-goose chase of trying to figure out how the Django context might have been responsible for the unexpected output, before realizing my basic logic error.&lt;/p&gt;

&lt;p&gt;This was fairly easily corrected (my updated code applies the datetime-mapping unconditionally to set of optionally-filtered results) but perfectly illustrates my issue with idiomatic python: while the language itself has constructs like &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt; that support the functional programming model, the language strongly steers you towards writing things in an imperative style that makes costly and annoying mistakes like this much easier to make. Yes, list and dictionary comprehensions are nice and compact but they start to break down in the more complex cases.&lt;/p&gt;

&lt;p&gt;As an experiment, I wrote up what this function might look like in a pure functional style with immutable data structures:&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transform_and_filter_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;new_build_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;new_build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromtimestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tz&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tzutc&lt;/span&gt;&lt;span class="p"&gt;())]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt;
        &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;build_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;min_time&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;new_build_data&lt;/span&gt;
&lt;span class="n"&gt;transformed_build_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;transform_and_filter_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;A work of art it isn&amp;rsquo;t &amp;mdash; and definitely not &amp;ldquo;pythonic&amp;rdquo;. Compare this to a similar piece of code written in Javascript (ES6) with lodash (using a hypothetical &lt;code&gt;tzified&lt;/code&gt; function):&lt;/p&gt;

&lt;div class="brush: js"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5
6
7&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;transformedBuildData&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;mapValues&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;buildData&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;minTimestamp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;tzcified&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])].&lt;/span&gt;&lt;span class="nx"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;datum&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;slice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="p"&gt;})),&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;buildId&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;A little bit easier to understand, but more importantly (to me anyway) it comes across as idiomatic and natural in a way that the python version just doesn&amp;rsquo;t. I&amp;rsquo;ve been happily programming Python for the last 10 years, but it&amp;rsquo;s increasingly feeling time to move on to greener pastures.&lt;/p&gt;</description></item>
  <item>
   <title>mozregression's new mascot</title>
   <link>https://wlach.github.io/blog/2017/07/mozregression-s-new-mascot?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-07-mozregression-s-new-mascot</guid>
   <pubDate>Mon, 31 Jul 2017 15:32:02 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Spent a few hours this morning on a few housekeeping issues with &lt;a href="https://mozilla.github.io/mozregression"&gt;mozregression&lt;/a&gt;. The web site was badly in need of an update (it was full of references to obsolete stuff like B2G and codefirefox.com) and the usual pile of fixes motivated a new release of the actual software. But most importantly, mozregression now has a proper application icon / logo, thanks to Victoria Wang!&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/07/mozregressionicon3.png" /&gt;&lt;/p&gt;

&lt;p&gt;One of the nice parts about working at Mozilla is the flexibility it offers to just hack on stuff that&amp;rsquo;s important, whether or not it&amp;rsquo;s part of your formal job description. Maintaining mozregression is pretty far outside my current set of responsibilities (or even interests), but I keep it going because it&amp;rsquo;s a key tool used by developers team here and no one else seems willing to take it over. Fortunately, tools like appveyor and pypi keep the time suckage to a mostly-reasonable level.&lt;/p&gt;</description></item>
  <item>
   <title>Taking over an npm package: sanity prevails</title>
   <link>https://wlach.github.io/blog/2017/07/taking-over-an-npm-package-sanity-prevails?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-07-taking-over-an-npm-package-sanity-prevails</guid>
   <pubDate>Thu, 13 Jul 2017 15:08:40 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Sometimes problems are easier to solve than expected.&lt;/p&gt;

&lt;p&gt;For the last few months I&amp;rsquo;ve been working on the front end of a new project called &lt;a href="https://github.com/mozilla/missioncontrol"&gt;Mission Control&lt;/a&gt;, which aims to chart lots of interesting live information in something approximating realtime. Since this is a greenfield project, I thought it would make sense to use the currently-invogue framework at Mozilla (react) along with our standard visualization library, &lt;a href="http://metricsgraphicsjs.org/"&gt;metricsgraphics&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Metricsgraphics is great, but its jquery-esque api is somewhat at odds with the react way. The obvious solution to this problem is to wrap its functionality in a react component, and a quick google search determined that several people have tried to do exactly that, the most popular one being one called (obviously) react-metrics-graphics. Unfortunately, it hadn&amp;rsquo;t been updated in quite some time and some pull requests (including ones implementing features I needed for my project) weren&amp;rsquo;t being responded to.&lt;/p&gt;

&lt;p&gt;I expected this to be pretty difficult to resolve: I had no interaction with the author (Carter Feldman) before but based on my past experiences in free software, I was expecting stonewalling, leaving me no choice but to fork the package and give it a new name, a rather unsatisfying end result.&lt;/p&gt;

&lt;p&gt;But, hey, let&amp;rsquo;s keep an open mind on this. What does google say about unmaintained npm packages? Oh what&amp;rsquo;s this? They actually have a &lt;a href="https://docs.npmjs.com/misc/disputes"&gt;policy&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;tl;dr: You email the maintainer (politely) and CC support@npmjs.org about your interest in helping maintain the software. If you&amp;rsquo;re unable to come up with a resolution on your own, they will intervene.&lt;/p&gt;

&lt;p&gt;So I tried that. It turns out that Carter was really happy to hear that Mozilla was interested in taking over maintenance of this project, and not only gave me permission to start publishing newer versions to npm, but even transferred his repository over to Mozilla (so we could preserve issue and PR history). The project&amp;rsquo;s new location is here:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/mozilla/react-metrics-graphics"&gt;https://github.com/mozilla/react-metrics-graphics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In hindsight, this is obviously the most reasonable outcome and I&amp;rsquo;m not sure why I was expecting anything else. Is the node community just friendlier than other areas I&amp;rsquo;ve worked in? Have community standards improved generally? In any case, thank you Carter for a great piece of software, hopefully it will thrive in its new home. :P&lt;/p&gt;</description></item>
  <item>
   <title>The vastness</title>
   <link>https://wlach.github.io/blog/2017/07/the-vastness?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-07-the-vastness</guid>
   <pubDate>Sat, 08 Jul 2017 14:25:33 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Had a good all hands with the rest of Mozilla in San Francisco (at least those able and willing to attend due to the current political situation in the U.S.). I stayed a few extra days to hang out with some of my friends who had moved to S.F. On Sunday we went to Muir Woods, where I took this picture:&lt;/p&gt;

&lt;p&gt;&lt;a href="/files/2017/07/muirwoods-20170702.jpg"&gt;&lt;img style="width:640px" src="/files/2017/07/muirwoods-20170702.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It occurred to me at the time that I took that photo that pretty much every sensory receptor in my optic nerve was registering the signal of some kind of life. Thousands of beings (trees, clover, moss, lichens) in turn made up of trillions upon trillions of tiny beings (cells, bacteria) all conscious and interacting with each other in ways that I can barely begin to understand.&lt;/p&gt;</description></item>
  <item>
   <title>Using Docker to run automated tests</title>
   <link>https://wlach.github.io/blog/2017/06/using-docker-to-run-automated-tests?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-06-using-docker-to-run-automated-tests</guid>
   <pubDate>Fri, 02 Jun 2017 20:04:38 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;A couple months ago, I joined the Mozilla Data Platform team, to work on our &lt;a href="https://wiki.mozilla.org/Telemetry"&gt;Telemetry&lt;/a&gt; and automated data collection services. This has been an interesting transition for me, and a natural jumping off point from my work on &lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder"&gt;Perfherder&lt;/a&gt;. Now, instead of manipulating mere 10s of gigabytes worth of fairly regular data, I&amp;rsquo;m working with 100s of terrabytes of noisy data with a much larger number of dimensions. :P It&amp;rsquo;s been interesting so far.&lt;/p&gt;

&lt;p&gt;One of the first things I decided to work on was improving our unit testing story around a few of our primary packages for data analysis/etl: &lt;a href="https://github.com/mozilla/python_moztelemetry/"&gt;python_moztelemetry&lt;/a&gt; (a library we use for running custom spark jobs against Telemetry data) and &lt;a href="https://github.com/mozilla/telemetry-batch-view/"&gt;telemetry-batch-view&lt;/a&gt; (a set of scala jobs we run against the main telemetry data store to create a useful set of aggregations that are easily queried with tools like &lt;a href="https://redash.io/"&gt;redash&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;It turns out that these tools interact with several larger / more involved pieces than I&amp;rsquo;m used to dealing with (such as hbase and thrift). For continuous integration/automation, we already had a set of travis scripts to install and reproduce the environment needed to test these parts, but there was no straightforward way to do this locally. My third time through creating an Ubuntu virtual machine environment to reproduce this environment locally (long story), I figured it was finally time for me to investigate using something to automate that setup procedure and make it easier for new developers to get into these projects.&lt;/p&gt;

&lt;p&gt;I hadn&amp;rsquo;t used it much before, but &lt;a href="https://docker.com"&gt;Docker&lt;/a&gt; seemed like a fairly obvious choice. Small, simple, and Linuxy? Sign me up.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m pretty happy with how things turned out, but there were a few caveats. Docker is more of a general purpose tool for building environments for running &lt;em&gt;things&lt;/em&gt;, whether that be an apache webserver or a jabber messaging doohickey (whereas e.g. something like travis is basically a domain-specific language for creating and running automated tests). There were a few tricks I needed to employ to make the whole testing process smooth in both cases, which I&amp;rsquo;ll document here for posterity:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;You can &lt;code&gt;ADD&lt;/code&gt; a set of files / directories to a docker environment inside your Dockerfile, but if you want your set of tests to pick up any changes made since the environment was created, you really should mount your testing directory inside the container using the &lt;code&gt;-v&lt;/code&gt; option.&lt;/li&gt;
 &lt;li&gt;If you need to download/install a piece of software when building the docker container, use the &lt;code&gt;RUN&lt;/code&gt; directive instead of &lt;code&gt;ADD&lt;/code&gt;. This will speed up rebuilding the container while you&amp;rsquo;re iterating on it (because you can take advantage of the Docker layers cache).&lt;/li&gt;
 &lt;li&gt;You almost certainly want to create a script (&lt;a href="https://github.com/mozilla/python_moztelemetry/blob/d2aa84bbac09465d38eeb0b5beb20edc7ddcc21b/runtests.sh"&gt;example&lt;/a&gt;) to streamline all the steps of running the tests: this will make running the tests easier for anyone wanting to contribute to your project and reduce the amount of documentation that you will have to write.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;The relevant files and documentation are in the repositories linked above.&lt;/p&gt;</description></item>
  <item>
   <title>Easier reproduction of intermittent test failures in automation</title>
   <link>https://wlach.github.io/blog/2017/04/easier-reproduction-of-intermittent-test-failures-in-automation?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-04-easier-reproduction-of-intermittent-test-failures-in-automation</guid>
   <pubDate>Wed, 05 Apr 2017 20:14:35 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;As part of the &lt;a href="https://wiki.mozilla.org/Auto-tools/Projects/Stockwell"&gt;Stockwell project&lt;/a&gt;, I&amp;rsquo;ve been hacking on ways to make it easier for developers to diagnose failure of our tests in automation. It&amp;rsquo;s often very difficult to reproduce an intermittent failure we see in Treeherder locally since the environment is so different, but historically it has been a big hassle to get access to the machines we use in automation for various reasons.&lt;/p&gt;

&lt;p&gt;One option that rolled out last year was the so-called one-click loaner, which enabled developers to sign out an virtual machine instance identical to the ones used to run unit tests (at least if the tests are running on Taskcluster, which is increasingly often the case), then execute their particular case with whatever extra debugging options they would find useful. This is a big step forward, but it&amp;rsquo;s still quite a bit of hassle, since it requires a bunch of manual work on the part of the developer to interact with the instance.&lt;/p&gt;

&lt;p&gt;What if we could &lt;em&gt;just&lt;/em&gt; re-run the particular test an arbitrary number of times with whatever options we wanted, simply by clicking on a few buttons on Treeherder? I&amp;rsquo;ve been exploring this for the first few months of 2017 and I&amp;rsquo;ve come up with a prototype which I think is ready for people to start playing with.&lt;/p&gt;

&lt;p&gt;The user interface to this is pretty straightforward. Just find a job you want to retrigger in Treeherder:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-selected-mochitest.png" /&gt;&lt;/p&gt;

&lt;p&gt;Then select the &amp;rsquo;&amp;hellip;&amp;rsquo; option in the panel below and press &amp;ldquo;Custom Action&amp;hellip;&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-taskcluster-options.png" /&gt;&lt;/p&gt;

&lt;p&gt;You should get a small piece of JSON to edit, which corresponds to the configuration for the retriggered job:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2017/04/treeherder-custom-action.png" /&gt;&lt;/p&gt;

&lt;p&gt;The main field to edit is &amp;ldquo;path&amp;rdquo;. You should set this to the name of the test you want to try retriggering. For example &lt;code&gt;dom/animation/test/css-transitions/test_animation-ready.html&lt;/code&gt;. You can also set custom Firefox preferences and environment variables, to turn on different types of debugging.&lt;/p&gt;

&lt;p&gt;Unfortunately as usual with a new feature at Mozilla, there are a bunch of limitations and caveats:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;This depends on functionality that&amp;rsquo;s only in Taskcluster, so  buildbot jobs are exempt.&lt;/li&gt;
 &lt;li&gt;No support for Android yet. In combination with the above  limitation, this implies that this functionality only works  on Linux (at least until other platforms are moved to Taskcluster,  which hopefully isn&amp;rsquo;t that far off).&lt;/li&gt;
 &lt;li&gt;Browser chrome tests failing in mysterious ways if run repeatedly  (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1347654"&gt;bug 1347654&lt;/a&gt;)&lt;/li&gt;
 &lt;li&gt;Only reftest and mochitest are currently supported. XPCShell  support is blocked by the lack of support in its harness for  running a job repeatedly (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1347696"&gt;bug 1347696&lt;/a&gt;).  Web Platform Tests need the requisite support in mozharness for  just setting up the tests without running them &amp;mdash; the same issue  that prevents us from debugging such tests with a one-click loaner  (&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1348833"&gt;bug 1348833&lt;/a&gt;).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Aside from fixing the above limitations, the following features would also be really nifty to have:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;Ability to trigger a custom job as part of a try push (i.e.  not needing to retrigger off an existing job)&lt;/li&gt;
 &lt;li&gt;Run these jobs under rr, and provide a way to login and  interactively debug when the problem is actually reproduced.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;I am actually in the process of moving to another team @ Mozilla (more on that in another post), so I probably won&amp;rsquo;t have a ton of time to work on the above &amp;mdash; but I&amp;rsquo;d be happy to help anyone who&amp;rsquo;s interested in developing this idea further.&lt;/p&gt;

&lt;p&gt;A special shout out to the &lt;a href="https://wiki.mozilla.org/TaskCluster"&gt;Taskcluster&lt;/a&gt; team for helping me with the development of this feature: in particular the action task implementation from &lt;a href="https://jonasfj.dk/"&gt;Jonas Finnemann Jensen&lt;/a&gt; that made it possible to develop this feature in the first place.&lt;/p&gt;</description></item>
  <item>
   <title>Cancel all the things</title>
   <link>https://wlach.github.io/blog/2017/02/cancel-all-the-things?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2017-02-cancel-all-the-things</guid>
   <pubDate>Tue, 07 Feb 2017 18:36:09 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;I just added a feature to Treeherder which lets you cancel a set of jobs (say, from a botched try push) much more easily. I&amp;rsquo;m hopeful that this will be helpful in keeping our resource usage on try more under control.&lt;/p&gt;

&lt;p&gt;It uses the &amp;ldquo;pinboard&amp;rdquo; feature of Treeherder which very few people are familiar with, so I made a very short video tutorial on how to make use of this feature and put it on the Joy of Automation channel:&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/ryzsy38yw5A" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;

&lt;p&gt;Happy cancelling!&lt;/p&gt;</description></item>
  <item>
   <title>Training an autoclassifier</title>
   <link>https://wlach.github.io/blog/2016/11/training-an-autoclassifier?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2016-11-training-an-autoclassifier</guid>
   <pubDate>Mon, 28 Nov 2016 21:29:47 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Here at Mozilla, we&amp;rsquo;ve accepted that a certain amount of intermittent failure in our automated testing of Firefox is to be expected. That is, for every push, a subset of the tests that we run will fail for reasons that have nothing to do with the quality (or lack thereof) of the push itself.&lt;/p&gt;

&lt;p&gt;On the main integration branches that developers commit code to, we have dedicated staff and volunteers called sheriffs who attempt to distinguish these expected failures from intermittents through a manual classification process using &lt;a href="https://treeherder.mozilla.org"&gt;Treeherder&lt;/a&gt;. On any given push, you can usually find some failed jobs that have stars beside them, this is the work of the sheriffs, indicating that a job&amp;rsquo;s failure is &amp;ldquo;nothing to worry about&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/11/treeherder-in-action.png" /&gt;&lt;/p&gt;

&lt;p&gt;This generally works pretty well, though unfortunately it doesn&amp;rsquo;t help developers who need to test their changes on Try, which have the same sorts of failures but no sheriffs to watch them or interpret the results. For this reason (and a few others which I won&amp;rsquo;t go into detail on here), there&amp;rsquo;s been much interest in having Treeherder autoclassify known failures.&lt;/p&gt;

&lt;p&gt;We have a partially implemented version that attempts to do this based on structured (failure line) information, but we&amp;rsquo;ve had some difficulty creating a reasonable user interface to train it. Sheriffs are used to being able to quickly tag many jobs with the same bug. Having to go through each job&amp;rsquo;s failure lines and manually annotate each of them is much more time consuming, at least with the approaches that have been tried so far.&lt;/p&gt;

&lt;p&gt;&lt;img src="/files/2016/11/treeherder-per-line-classification.png" /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s quite possible that this is a solvable problem, but I thought it might be an interesting exercise to see how far we could get training an autoclassifier with only the existing per-job classifications as training data. With some recent work I&amp;rsquo;ve done on refactoring Treeherder&amp;rsquo;s database, getting a complete set of per-job failure line information is only a small SQL query away:&lt;/p&gt;

&lt;div class="brush: sql"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bug_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;bug_job_map&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;
  &lt;span class="k"&gt;left&lt;/span&gt; &lt;span class="k"&gt;join&lt;/span&gt; &lt;span class="n"&gt;text_log_step&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;job_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;job_id&lt;/span&gt;
  &lt;span class="k"&gt;left&lt;/span&gt; &lt;span class="k"&gt;join&lt;/span&gt; &lt;span class="n"&gt;text_log_error&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tls&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;
  &lt;span class="k"&gt;where&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;created&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2016-10-31&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;created&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2016-11-24&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bug_id&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="k"&gt;not&lt;/span&gt; &lt;span class="k"&gt;NULL&lt;/span&gt;
  &lt;span class="k"&gt;order&lt;/span&gt; &lt;span class="k"&gt;by&lt;/span&gt; &lt;span class="n"&gt;bjm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tle&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Just to give some explanation of this query, the &amp;ldquo;bug_job_map&amp;rdquo; provides a list of bugs that have been applied to jobs. The &amp;ldquo;text_log_step&amp;rdquo; and &amp;ldquo;text_log_error&amp;rdquo; tables contain the actual errors that Treeherder has extracted from the textual logs (to explain the failure). From this raw list of mappings and errors, we can construct a data structure incorporating the job, the assigned bug and the textual errors inside it. For example:&lt;/p&gt;

&lt;div class="brush: json"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="nt"&gt;"bug_number"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1202623&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="nt"&gt;"lines"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Found a tab after previous test timed out: http:/&amp;lt;number&amp;gt;&amp;lt;number&amp;gt;:&amp;lt;number&amp;gt;/browser/browser/base/content/test/plugins/plugin_test.html -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_private_clicktoplay.js A promise chain failed to handle a rejection:  - at chrome://mochikit/content/browser-test.js:&amp;lt;number&amp;gt; - TypeError: this.SimpleTest.isExpectingUncaughtException is not a function"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window after previous test timed out -"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s2"&gt;"browser_privatebrowsing_newtab_from_popup.js Found a browser window&lt;/span&gt;
&lt;span class="s2"&gt;  after previous test timed out -"&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Some quick google searching revealed that &lt;a href="http://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; is a popular tool for experimenting with text classifications. They even had a &lt;a href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"&gt;tutorial&lt;/a&gt; on classifying newsgroup posts which seemed tantalizingly close to what we needed to do here. In that example, they wanted to predict which newsgroup a post belonged to based on its content. In our case, we want to predict which existing bug a job failure should belong to based on its error lines.&lt;/p&gt;

&lt;p&gt;There are obviously some differences in our domain: test failures are much more regular and structured. There are lots of numbers in them which are mostly irrelevant to the classification (e.g. the &amp;ldquo;expected 12 pixels different, got 10!&amp;rdquo; type errors in reftests). Ordering of failures might matter. Still, some of the techniques used on corpora of normal text documents for training a classifier probably map nicely onto what we&amp;rsquo;re trying to do here: it seems plausible that weighting words which occur more frequently less strongly against ones that are less common would be helpful, for example, and that&amp;rsquo;s one thing their default transformers does.&lt;/p&gt;

&lt;p&gt;In any case, I built up a small little script to download a subset of the downloaded data (from November 1st to November 23rd), used it as training data for a classifier, then tested that against another subset of test failures between November 24th and 28th.&lt;/p&gt;

&lt;div class="brush: py"&gt;
 &lt;table class="sourcetable"&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td class="linenos"&gt;
     &lt;div class="linenodiv"&gt;
      &lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;
    &lt;td class="code"&gt;
     &lt;div class="source"&gt;
      &lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_files&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfTransformer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SGDClassifier&lt;/span&gt;


&lt;span class="n"&gt;training_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_files&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;training&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;count_vect&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountVectorizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X_train_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_vect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfTransformer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X_train_tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train_counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SGDClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hinge&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;penalty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;l2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train_tfidf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;num_missed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;walk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;testing/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;bugnum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;bugnum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fname&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;fnames&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fname&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; (skipping, empty)"&lt;/span&gt;
            &lt;span class="n"&gt;X_new_counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_vect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;X_new_tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_new_counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;training_set&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target_names&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_new_tfidf&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;bugnum&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; correct"&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_missed&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"--&amp;gt; missed (&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;)"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;predicted_bugnum&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"Correct: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; Missed: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; Ratio: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_correct&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_missed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_correct&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;num_missed&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;With absolutely no tweaking whatsoever, I got an accuracy rate of 75% on the test data. That is, the algorithm chose the correct classification given the failure text 1312 times out of 1959. Not bad for a first attempt!&lt;/p&gt;

&lt;p&gt;After getting that working, I did some initial testing to see if I could get better results by reusing some of the error ETL summary code in Treeherder we use for bug suggestions, but the results were pretty much the same.&lt;/p&gt;

&lt;p&gt;So what&amp;rsquo;s next? This seems like a wide open area to me, but some initial areas that seem worth exploring, if we wanted to take this idea further:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;Investigate cases where the autoclassification failed or had a near miss. Is there a pattern here? Is there something simple we could do, either by tweaking the input data or using a better vectorizer/tokenizer?&lt;/li&gt;
 &lt;li&gt;Have a confidence threshold for using the autoclassifier&amp;rsquo;s data. It seems likely to me that many of the cases above where we got the wrong were cases where the classifier itself wasn&amp;rsquo;t that confident in the result (vs. others). We can either present that in the user interface or avoid classifications for these cases altogether (and leave it up to a human being to make a decision on whether this is an intermittent).&lt;/li&gt;
 &lt;li&gt;Using the structured log data inside the database as input to a classifier. Structured log data here is much more regular and denser than the free text that we&amp;rsquo;re using. Even if it isn&amp;rsquo;t explicitly classified, we may well get better results by using it as our input data.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;If you&amp;rsquo;d like to experiment with the data and/or code, I&amp;rsquo;ve put it up on a &lt;a href="https://github.com/wlach/treeherder-classifier"&gt;github repository&lt;/a&gt;.&lt;/p&gt;</description></item>
  <item>
   <title>Slow Treeherder, Fast Treeherder</title>
   <link>https://wlach.github.io/blog/2016/10/slow-treeherder-fast-treeherder?utm_source=all&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:https-wlach-github-io:-blog-2016-10-slow-treeherder-fast-treeherder</guid>
   <pubDate>Mon, 31 Oct 2016 15:40:00 UT</pubDate>
   <author>William Lachance</author>
   <description>
&lt;p&gt;Just wanted to talk about some recent performance improvements we&amp;rsquo;ve made recently to &lt;a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Treeherder"&gt;Treeherder&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1311511"&gt;Bug 1311511&lt;/a&gt;: Changed the repository endpoint so we don&amp;rsquo;t do 40 redundant database  queries (this was generally innocuous, but could delay loading by  400ms if the database was under heavy load).&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1310016"&gt;Bug 1310016&lt;/a&gt;: Persisted database connections across requests (this  can save ~40&amp;ndash;50ms per request, of which there can be 5&amp;ndash;10  when loading a Treeherder page).&lt;/li&gt;
 &lt;li&gt;&lt;a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1308782"&gt;Bug 1308782&lt;/a&gt;: &lt;em&gt;Don&amp;rsquo;t&lt;/em&gt; download job type and group information  from the server to get a &amp;ldquo;sorting order&amp;rdquo; for the job lists. This was  never necessary, but it&amp;rsquo;s gotten exponentially more painful as  people have added job types to Treeherder (job type information is  now around a megabyte of JSON these days). This saves 5&amp;ndash;10 seconds on a  typical page load.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;There&amp;rsquo;s more to come, but with these changes Treeherder should be faster for everyone to load. It should be particularly noticeable on try pushes, where the last item was by far the largest bottleneck. Here&amp;rsquo;s a youtube video of the changes:&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/xNJGoZhA4Vs" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;

&lt;p&gt;The original is on the left. The newer, faster Treeherder is on the right. Pay particular attention to how much faster the job information populates.&lt;/p&gt;

&lt;p&gt;Moral of the story? Optimization can be helpful, but it&amp;rsquo;s better if you can avoid doing the work altogether.&lt;/p&gt;</description></item></channel></rss>