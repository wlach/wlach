<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <title>William Lachance's Log (page 8)</title>
    <meta name="description" content="William Lachance's Log (page 8)">
    <meta name="author"      content="William Lachance">
    <meta name="keywords"    content="Taskcluster, FirefoxOS, Web, Philosophy, Data, Metrics Graphics, Mozilla, all, Profiling, BIXI, Community, Iodide, Life, Video, Meditation, iphone, GoFaster, Bikes, Social Media, Business, Android, Treeherder, GNOME, Environment, Île Sans Fil, Time, Psychology, Statistics, zen, Music, Counting, Buddhism, Eideticker, Usability, Transit to Go, Infraherder, Ebola, Orangutan, Open Data, Nixi, Meta, ateam, Perfherder, Montreal, Docker, Talos, Telemetry, Responsiveness, Glean, Pandaboard, Food, Toronto, Mission Control, Coffee, hbus, Python, Cats, email, Data Visualization, WifiDog, SQL, Release Engineering, Polling, Performance, Free Software, Transit, mozregression, MSF">
    <meta name="viewport"    content="width=device-width, initial-scale=1.0">
    <link rel="icon"      href="/favicon.ico">
    <link rel="canonical" href="https://wlach.github.io/index-8.html">


    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="/css/pygments.css">
    <link rel="stylesheet" type="text/css" href="/css/scribble.css">
    <link rel="stylesheet" type="text/css" href="/css/custom.css">
    <!-- Feeds -->
    <link rel="alternate" type="application/atom+xml"
          href="/feeds/all.atom.xml" title="Atom Feed">
    <link rel="alternate" type="application/rss+xml"
          href="/feeds/all.rss.xml" title="RSS Feed">
    <!-- JS -->
    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-xxxxx', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <!-- A standard Twitter Bootstrap nav bar -->
    <header class="navbar navbar-default navbar-inverse"
            role="banner">
      <div class="container">
        <div class="navbar-header">
          <button type="button"
                  class="navbar-toggle"
                  data-toggle="collapse"
                  data-target=".our-nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a href="/index.html" class="navbar-brand">William Lachance's Log</a>
        </div>
        <div class="collapse navbar-collapse our-nav-collapse"
             role="navigation">
          <ul class="nav navbar-nav">

            <li class="dropdown">
              <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                Tags <b class="caret"></b></a>
              <ul class="dropdown-menu">
                <li><a href="/index.html">All Posts</a></li>

<li><a href="/tags/Android.html">Android</a></li>

<li><a href="/tags/ateam.html">ateam</a></li>

<li><a href="/tags/Bikes.html">Bikes</a></li>

<li><a href="/tags/BIXI.html">BIXI</a></li>

<li><a href="/tags/Buddhism.html">Buddhism</a></li>

<li><a href="/tags/Business.html">Business</a></li>

<li><a href="/tags/Cats.html">Cats</a></li>

<li><a href="/tags/Coffee.html">Coffee</a></li>

<li><a href="/tags/Community.html">Community</a></li>

<li><a href="/tags/Counting.html">Counting</a></li>

<li><a href="/tags/Data.html">Data</a></li>

<li><a href="/tags/Data-Visualization.html">Data Visualization</a></li>

<li><a href="/tags/Docker.html">Docker</a></li>

<li><a href="/tags/Ebola.html">Ebola</a></li>

<li><a href="/tags/Eideticker.html">Eideticker</a></li>

<li><a href="/tags/email.html">email</a></li>

<li><a href="/tags/Environment.html">Environment</a></li>

<li><a href="/tags/FirefoxOS.html">FirefoxOS</a></li>

<li><a href="/tags/Food.html">Food</a></li>

<li><a href="/tags/Free-Software.html">Free Software</a></li>

<li><a href="/tags/Glean.html">Glean</a></li>

<li><a href="/tags/GNOME.html">GNOME</a></li>

<li><a href="/tags/GoFaster.html">GoFaster</a></li>

<li><a href="/tags/hbus.html">hbus</a></li>

<li><a href="/tags/Infraherder.html">Infraherder</a></li>

<li><a href="/tags/Iodide.html">Iodide</a></li>

<li><a href="/tags/iphone.html">iphone</a></li>

<li><a href="/tags/Life.html">Life</a></li>

<li><a href="/tags/Meditation.html">Meditation</a></li>

<li><a href="/tags/Meta.html">Meta</a></li>

<li><a href="/tags/Metrics-Graphics.html">Metrics Graphics</a></li>

<li><a href="/tags/Mission-Control.html">Mission Control</a></li>

<li><a href="/tags/Montreal.html">Montreal</a></li>

<li><a href="/tags/Mozilla.html">Mozilla</a></li>

<li><a href="/tags/mozregression.html">mozregression</a></li>

<li><a href="/tags/MSF.html">MSF</a></li>

<li><a href="/tags/Music.html">Music</a></li>

<li><a href="/tags/Nixi.html">Nixi</a></li>

<li><a href="/tags/Open-Data.html">Open Data</a></li>

<li><a href="/tags/Orangutan.html">Orangutan</a></li>

<li><a href="/tags/Pandaboard.html">Pandaboard</a></li>

<li><a href="/tags/Perfherder.html">Perfherder</a></li>

<li><a href="/tags/Performance.html">Performance</a></li>

<li><a href="/tags/Philosophy.html">Philosophy</a></li>

<li><a href="/tags/Polling.html">Polling</a></li>

<li><a href="/tags/Profiling.html">Profiling</a></li>

<li><a href="/tags/Psychology.html">Psychology</a></li>

<li><a href="/tags/Python.html">Python</a></li>

<li><a href="/tags/Release-Engineering.html">Release Engineering</a></li>

<li><a href="/tags/Responsiveness.html">Responsiveness</a></li>

<li><a href="/tags/Social-Media.html">Social Media</a></li>

<li><a href="/tags/SQL.html">SQL</a></li>

<li><a href="/tags/Statistics.html">Statistics</a></li>

<li><a href="/tags/Talos.html">Talos</a></li>

<li><a href="/tags/Taskcluster.html">Taskcluster</a></li>

<li><a href="/tags/Telemetry.html">Telemetry</a></li>

<li><a href="/tags/Time.html">Time</a></li>

<li><a href="/tags/Toronto.html">Toronto</a></li>

<li><a href="/tags/Transit.html">Transit</a></li>

<li><a href="/tags/Transit-to-Go.html">Transit to Go</a></li>

<li><a href="/tags/Treeherder.html">Treeherder</a></li>

<li><a href="/tags/Usability.html">Usability</a></li>

<li><a href="/tags/Video.html">Video</a></li>

<li><a href="/tags/Web.html">Web</a></li>

<li><a href="/tags/WifiDog.html">WifiDog</a></li>

<li><a href="/tags/zen.html">zen</a></li>

<li><a href="/tags/I%CC%82le-Sans-Fil.html">Île Sans Fil</a></li>
              </ul>
            </li>
            <li>
              <a href="/About.html">About</a>
            </li> 
            <li><a href="/feeds/all.atom.xml">Atom</a></li>
            <li><a href="/feeds/all.rss.xml">RSS</a></li>
          </ul>
        </div>
      </div>
    </header>
    <div class="container">
      <div class="row">

        <!-- Main column -->
        <div id="content" class="col-md-12">



          <article>
  <header>
    <p><span class="tags"><a href="/tags/Data-Visualization.html">Data Visualization</a>, <a href="/tags/Eideticker.html">Eideticker</a>, <a href="/tags/FirefoxOS.html">FirefoxOS</a>, <a href="/tags/Mozilla.html">Mozilla</a></span></p>
    <h2><a href='/blog/2013/10/automatically-measuring-startup-load-time-with-eideticker/'>Automatically measuring startup / load time with Eideticker</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Oct 17th, 2013</p>
  </header>

<p>So we&#8217;ve been using Eideticker to automatically measure startup/pageload times for about a year now on Android, and more recently on FirefoxOS as well (albeit not automatically). This gives us nice and pretty graphs like this:</p>

<p><a href="/files/2013/10/flot-startup-times-gn.png"><img src="/files/2013/10/flot-startup-times-gn.png" alt="flot-startup-times-gn" width="620" height="568" class="alignnone size-full wp-image-986" srcset="/files/2013/10/flot-startup-times-gn-300x274.png 300w, /files/2013/10/flot-startup-times-gn.png 620w" sizes="(max-width: 620px) 100vw, 620px" /></a></p>

<p>Ok, so we&#8217;re generating numbers and graphing them. That&#8217;s great. But what&#8217;s really going on behind the scenes? I&#8217;m glad you asked. The story is a bit different depending on which platform you&#8217;re talking about.</p>

<p><strong>Android</strong></p>

<p>On Android we connect Eideticker to the device&#8217;s HDMI out, so we count on a nearly pixel-perfect signal. In practice, it isn&#8217;t quite, but it is within a few RGB values that we can easily filter for. This lets us come up with a pretty good mechanism for determining when a page load or app startup is finished: just compare frames, and say we&#8217;ve &#8220;stopped&#8221; when the pixel differences between frames are negligible (previously defined at 2048 pixels, now 4096 &#8212; see below). Eideticker&#8217;s new frame difference view lets us see how this works. Look at this graph of application startup:</p>

<p><a href="/files/2013/10/frame-difference-android-startup.png"><img src="/files/2013/10/frame-difference-android-startup.png" alt="frame-difference-android-startup" width="803" height="514" class="alignnone size-full wp-image-973" srcset="/files/2013/10/frame-difference-android-startup-300x192.png 300w, /files/2013/10/frame-difference-android-startup.png 803w" sizes="(max-width: 803px) 100vw, 803px" /></a>
 <br /><a href="http://eideticker.wrla.ch/#/samsung-gn/startup-abouthome-dirty/timetostableframe">[Link to original]</a></p>

<p>What&#8217;s going on here? Well, we see some huge jumps in the beginning. This represents the animated transitions that Android makes as we transition from the SUTAgent application (don&#8217;t ask) to the beginnings of the FirefoxOS browser chrome. You&#8217;ll notice though that there&#8217;s some more changes that come in around the 3 second mark. This is when the site bookmarks are fully loaded. If you load the original page (link above) and swipe your mouse over the graph, you can see what&#8217;s going on for yourself.</p>

<p>This approach is not completely without problems. It turns out that there is sometimes some minor churn in the display even when the app is for all intents and purposes started. For example, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=922770">sometimes the scrollbar fading out of view can result in a significantish pixel value change</a>, so I recently upped the threshold of pixels that are different from 2048 to 4096. We also recently encountered a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=926997">silly problem</a> with a random automation app displaying &#8220;toasts&#8221; which caused results to artificially spike. More tweaking may still be required. However, on the whole I&#8217;m pretty happy with this solution. It gives useful, undeniably objective results whose meaning is easy to understand.</p>

<p><strong>FirefoxOS</strong></p>

<p>So as mentioned previously, we use a camera on FirefoxOS to record output instead of HDMI output. Pretty unsurprisingly, this is much noisier. See this movie of the contacts app starting and note all the random lighting changes, for example:</p>

<div style="width: 409px; " class="wp-video"><!--[if lt IE 9]><![endif]-->
 <video class="wp-video-shortcode" id="video-972-1" width="409" height="580" preload="metadata" controls="controls">
  <source type="video/webm" src="/files/2013/10/contacts-b2g-aug30-load-taphomescreen1.webm?_=1" /> <a href="/files/2013/10/contacts-b2g-aug30-load-taphomescreen1.webm">/files/2013/10/contacts-b2g-aug30-load-taphomescreen1.webm</a></video></div>

<p>My experience has been that pixel differences can be so great between visually identical frames on an eideticker capture on these devices that it&#8217;s pretty much impossible to settle on when startup is done using the frame difference method. It&#8217;s of course possible to detect very large scale changes, but the small scale ones (like the contacts actually appearing in the example above) are very hard to distinguish from random differences in the amount of light absorbed by the camera sensor. Tricks like using median filtering (a.k.a. &#8220;blurring&#8221;) help a bit, but not much. Take a look at this graph, for example:</p>

<p><a href="/files/2013/10/plotly-contacts-load-pixeldiff.png"><img src="/files/2013/10/plotly-contacts-load-pixeldiff.png" alt="plotly-contacts-load-pixeldiff" width="531" height="679" class="alignnone size-full wp-image-980" srcset="/files/2013/10/plotly-contacts-load-pixeldiff-234x300.png 234w, /files/2013/10/plotly-contacts-load-pixeldiff.png 531w" sizes="(max-width: 531px) 100vw, 531px" /></a>
 <br /><a href="https://plot.ly/~WilliamLachance/3">[Link to original]</a></p>

<p>You&#8217;ll note that the pixel differences during &#8220;static&#8221; parts of the capture are highly variable. This is because the pixel difference depends heavily on how &#8220;bright&#8221; each frame is: parts of the capture which are black (e.g. a contacts icon with a black background) have a much lower difference between them than parts that are bright (e.g. the contacts screen fully loaded).</p>

<p>After a day or so of experimenting and research, I settled on an approach which seems to work pretty reliably. Instead of comparing the frames directly, I measure the <a href="http://en.wikipedia.org/wiki/Entropy">entropy</a> of the <a href="http://en.wikipedia.org/wiki/Image_histogram">histogram</a> of colours used in each frame (essentially just an indication of brightness in this case, see <a href="http://brainacle.com/calculating-image-entropy-with-python-how-and-why.html">this article</a> for more on calculating it), then compare that of each frame with the average of the same measure over 5 previous frames (to account for the fact that two frames may be arbitrarily different, but that is unlikely that a sequence of frames will be). This seems to work much better than frame difference in this environment: although there are plenty of minute differences in light absorption in a capture from this camera, the overall color composition stays mostly the same. See this graph:</p>

<p><a href="/files/2013/10/plotly-contacts-load-entropy.png"><img src="/files/2013/10/plotly-contacts-load-entropy.png" alt="plotly-contacts-load-entropy" width="546" height="674" class="alignnone size-full wp-image-979" srcset="/files/2013/10/plotly-contacts-load-entropy-243x300.png 243w, /files/2013/10/plotly-contacts-load-entropy.png 546w" sizes="(max-width: 546px) 100vw, 546px" /></a>
 <br /><a href="https://plot.ly/~WilliamLachance/5">[Link to original]</a></p>

<p>If you look closely, you can see some minor variance in the entropy differences depending on the state of the screen, but it&#8217;s not nearly as pronounced as before. In practice, I&#8217;ve been able to get extremely consistent numbers with a reasonable &#8220;threshold&#8221; of &#8220;0.05&#8221;.</p>

<p>In Eideticker I&#8217;ve tried to steer away from using really complicated math or algorithms to measure things, unless all the alternatives fail. In that sense, I really liked the simplicity of &#8220;pixel differences&#8221; and am not thrilled about having to resort to this: hopefully the concepts in this case (histograms and entropy) are simple enough that most people will be able to understand my methodology, if they care to. Likely I will need to come up with something else for measuring responsiveness and animation smoothness (frames per second), as likely we can&#8217;t count on light composition changing the same way for those cases. My initial thought was to use <a href="http://en.wikipedia.org/wiki/Edge_detection">edge detection</a> (which, while somewhat complex to calculate, is at least easy to understand conceptually) but am open to other ideas.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>, <a href="/tags/Mozilla.html">Mozilla</a>, <a href="/tags/Responsiveness.html">Responsiveness</a></span></p>
    <h2><a href='/blog/2013/10/first-eideticker-responsiveness-tests/'>First Eideticker Responsiveness Tests</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Oct 7th, 2013</p>
  </header>

<p><em>[ For more information on the Eideticker software I&#8217;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>Time for another update on Eideticker. In the last quarter, I&#8217;ve been working on two main items:</p>

<ol>
 <li>Responsiveness tests (Android / FirefoxOS)</li>
 <li>Eideticker for FirefoxOS</li></ol>

<p>The focus of this post is the responsiveness work. I&#8217;ll talk about Eideticker for FirefoxOS soon.</p>

<p>So what do I mean by responsiveness? At a high-level, I mean how quickly one sees a response after performing an action on the device. For example, if I perform a swipe gesture to scroll the content down while browsing CNN.com, how long does it take after
 <br />I start the gesture for the content to <em>visibly</em> scroll down? If you break it down, there&#8217;s a multi-step process that happens behind the scenes after a user action like this:</p>

<p><a href="/files/2013/10/input-events.png"><img src="/files/2013/10/input-events.png" alt="input-events" width="880" height="752" class="alignnone size-full wp-image-957" srcset="/files/2013/10/input-events-300x256.png 300w, /files/2013/10/input-events.png 880w" sizes="(max-width: 880px) 100vw, 880px" /></a></p>

<p>If anywhere in the steps above, there is a significant delay, the user experience is likely to be bad. Usability research
 <br />suggests that any lag that is consistently above 100 milliseconds will lead the user to <a href="http://stackoverflow.com/questions/536300/what-is-the-shortest-perceivable-application-response-delay">perceive things as being laggy</a>. To keep our users happy, we need to do our bit to make sure that we respond quickly at all levels that we control (just the application layer on Android, but pretty much everything on FirefoxOS). Even if we can&#8217;t complete the work required on our end to completely respond to the user&#8217;s desire, we should at least display something to acknowledge that things have changed.</p>

<p>But you can&#8217;t improve what you can&#8217;t measure. Fortunately, we have the means to do calculate of the time delta between <em>most</em> of the steps above. I learned from <a href="http://taras.glek.net/">Taras Glek</a> this weekend that it should be <a href="http://hackaday.com/2012/05/04/reaching-out-to-a-touch-screen-with-a-microcontroller/">possible to simulate</a> the actual capacitative touch event on a modern touch screen. We can recognize when the hardware event is available to be consumed by userspace by monitoring the `/dev/input` subsystem. And once the event reaches the application (the Android or FirefoxOS application) there&#8217;s no reason we can&#8217;t add instrumentation in all sorts of places to track the processing of both the event and the rendering of the response.</p>

<p>My working hypothesis is that it&#8217;s application-level latency (i.e. the time between the application receiving the event and being able to act on it) that dominates, so that&#8217;s what I decided to measure. This is purely based on intuition and by no means proven, so we should test this (it would certainly be an interesting exercise!). However, even if it turns out that there are significant problems here, we still care about the other bits of the stack &#8212; there&#8217;s lots of potentially-latency-introducing churn there and the risk of regression in our own code is probably higher than it is elsewhere since it changes so much.</p>

<p>Last year, I wrote up a tool called <a href="http://wrla.ch/blog/2012/07/the-evolution-of-simulating-events-in-eideticker-from-monkeys-to-orangutns/?utm_source=rss&amp;#038;utm_medium=rss&amp;#038;utm_campaign=the-evolution-of-simulating-events-in-eideticker-from-monkeys-to-orangutns">Orangutan</a> that can directly inject input events into an input device on Android or FirefoxOS. It seemed like a fairly straightforward extension of the tool to output timestamps when these events were registered. It was. Then, by <a href="http://wrla.ch/blog/2013/07/simple-command-line-ntp-client-for-android-and-firefoxos/">synchronizing the time</a> between the device and the machine doing the capturing, we can then correlate the input timestamps to events. To help visualize what&#8217;s going on, I generated this view:</p>

<p><a href="/files/2013/10/taskjs-framediff-view.png"><img src="/files/2013/10/taskjs-framediff-view.png" alt="taskjs-framediff-view" width="583" height="418" class="alignnone size-full wp-image-962" srcset="/files/2013/10/taskjs-framediff-view-300x215.png 300w, /files/2013/10/taskjs-framediff-view.png 583w" sizes="(max-width: 583px) 100vw, 583px" /></a></p>

<p><a href="http://eideticker.wrla.ch/framediff-view.html?title=Frame%20Difference%20Scrolling%20on%20taskjs.org%20%282013-10-06%29&amp;#038;video=videos/video-1381129971.63.webm&amp;#038;framediff=framediffs/framediff-1381129990.79.json&amp;#038;actionlog=actionlogs/action-log-1381129990.79.json">[Link to original]</a></p>

<p>The X axis in that graph represents time. The Y-axis represents the difference between the frame at that time with the previous one in number of pixels. The &#8220;red&#8221; represents periods in capture when events are ongoing (we use different colours only to
 <br />distinguish distinct events). <sup><a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">1</a></sup></p>

<p>For a first pass at measuring responsiveness, I decided to measure the time between the first event being initiated and there being a significant frame difference (i.e. an observable response to the action). You can see some preliminary results on the eideticker dashboard:</p>

<p><a href="/files/2013/10/taskjs-responsiveness.png"><img src="/files/2013/10/taskjs-responsiveness.png" alt="taskjs-responsiveness" width="637" height="540" class="alignnone size-full wp-image-956" srcset="/files/2013/10/taskjs-responsiveness-300x254.png 300w, /files/2013/10/taskjs-responsiveness.png 637w" sizes="(max-width: 637px) 100vw, 637px" /></a></p>

<p><a href="http://eideticker.mozilla.org/#/samsung-gn/taskjs/timetoresponse">[Link to original]</a></p>

<p>The results seem pretty highly variable at first because I was synchronizing time between the device and an external ntp server, rather than the host machine. I believe this is now fixed, hopefully giving us results that will indicate when regressions occur. As time goes by, we may want to craft some special eideticker tests for responsiveness specifically (e.g. a site where there is heavy javascript background processing).</p>

<p><sup><a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">1</a></sup> <em>Incidentally, these &#8220;frame difference&#8221; graphs are also quite useful for understanding where and how application startup has regressed in Fennec &#8212; try opening these two startup views side-by-side (before/after a large regression) and spot the difference: <a href="http://eideticker.wrla.ch/framediff-view.html?title=Frame%20Difference%20Startup%20to%20about:home%20%28dirty%20profile%29%20%282013-08-20%29&amp;#038;video=videos/video-1377070981.95.webm&amp;#038;framediff=framediffs/framediff-1377070991.95.json">[1]</a> and <a href="http://eideticker.wrla.ch/framediff-view.html?title=Frame%20Difference%20Startup%20to%20about:home%20%28dirty%20profile%29%20%282013-08-23%29&amp;#038;video=videos/video-1377330042.28.webm&amp;#038;framediff=framediffs/framediff-1377330051.67.json">[2]</a>)</em></p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Philosophy.html">Philosophy</a></span></p>
    <h2><a href='/blog/2013/09/early-morning-questions/'>Early morning questions</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Sep 25th, 2013</p>
  </header>

<p>Last night while I was lying in bed the mystery of my being here, present, again occurred to me. Pondered that a bit upon waking up. Let me formulate two mysteries that, as far as I know, no one has given really satisfactory answers to:</p>

<ol>
 <li>Why does anything exist at all? And given that things do exist, why should they take the form that they do (planets, suns, nebulae, even life)?</li>
 <li>What accounts for the &#8220;subjectivity&#8221; of experience? That is, why is life not only here, but (in humanity&#8217;s case at least, probably in the case of other higher-order life, and possibly all life) there is a *conscious* experience that goes on with our perceptions of the world? It does not seem necessary for (1), does it?</li></ol>

<p>Perhaps the answer here is just that the way our minds (and hence anything we could form into thought or language) is based on descriptions of the world according to our perception. But (1) and (2) are in a sense, beyond this. I think in the case of (1) it is obvious why. In the case of (2) this might just be a limitation of our language/thought &#8212; certainly we can express that someone/something is conscious in a 3rd party sort of way (i.e. &#8220;she perceived red&#8221;), though this does not (as far as I can tell) express the <em>realness</em> of the experience. It&#8217;s a description, not the experience. To really understand experience from a 3rd person perspective (and hence why it exists?), you would need to go outside experience &#8212; but description <em>is part of</em> experience! The concept of being outside of it makes no sense.</p>

<p>[ Maybe I am just restating <a href="http://en.wikipedia.org/wiki/Immanuel_Kant">Kant</a> here ]</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Coffee.html">Coffee</a>, <a href="/tags/Environment.html">Environment</a></span></p>
    <h2><a href='/blog/2013/09/how-to-make-great-coffee-that-doesn-8217-t-generate-966-million-pounds-of-waste-a-year/'>How to make great coffee that doesn&#8217;t generate 966 million pounds of waste a year</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Sep 17th, 2013</p>
  </header>

<p>I was kind of appalled today to see this:</p>

<p><a href="/files/2013/09/Story-of-Stuff-Picture.png"><img src="/files/2013/09/Story-of-Stuff-Picture.png" alt="Story of Stuff Picture" width="720" height="720" class="alignnone size-full wp-image-936" srcset="/files/2013/09/Story-of-Stuff-Picture-150x150.png 150w, /files/2013/09/Story-of-Stuff-Picture-300x300.png 300w, /files/2013/09/Story-of-Stuff-Picture.png 720w" sizes="(max-width: 720px) 100vw, 720px" /></a></p>

<p>I initially thought this had to be a tall tale told by hippies, but doing a back of the envelope calculation, I realized that such a figure is entirely possible. Assume each packet weighs 0.05 pounds. Typing that into python I get:
 <br /><code>&lt;br /&gt;
&gt;&gt;&gt; 966*(10**6)/0.05&lt;br /&gt;
19320000000.0</code></p>

<p>19 billion packets. Seems awfully big. But divide that by, say, 10 million people:</p>

<p><code>&gt;&gt;&gt; x = 966*(10**6)/0.05&lt;br /&gt;
&gt;&gt;&gt; x/10**7&lt;br /&gt;
1932.0</code></p>

<p>1932 cups. Hmm, still seems big. That&#8217;s more than 5 cups a day. But if we say 30 million people are drinking this stuff, we rapidly get to the zone of plausibility.</p>

<p>People, it doesn&#8217;t have to be this way. You can have <em>way better</em> coffee that produces <em>zero</em> waste for only marginally more effort. Allow me to present the Will method of coffee production. First off, you use this thing:</p>

<p><a href="/files/2013/09/bialetti_coffee_maker.jpg"><img src="/files/2013/09/bialetti_coffee_maker-767x1024.jpg" alt="bialetti_coffee_maker" width="640" height="854" class="alignnone size-large wp-image-934" srcset="/files/2013/09/bialetti_coffee_maker-224x300.jpg 224w, /files/2013/09/bialetti_coffee_maker-767x1024.jpg 767w, /files/2013/09/bialetti_coffee_maker.jpg 800w" sizes="(max-width: 640px) 100vw, 640px" /></a></p>

<p>I have tried alternatives: french presses, filter coffee, &#8220;cowboy&#8221; percolators, even &#8220;professional&#8221; espresso makers. I maintain that the Bialetti filter produces the best cup of coffee: one full cup of espresso goodness. Not too strong, not too weak. Just perfect. Add some milk and you have an amazing caf&eacute; au lait. Of course, part of getting the best cup is using the right beans. If you&#8217;re brewing at home, you can afford to go a little fancy. Here&#8217;s what I&#8217;m currently using:</p>

<p><a href="/files/2013/09/portlandia_coffee.jpg"><img src="/files/2013/09/portlandia_coffee-767x1024.jpg" alt="portlandia_coffee" width="640" height="854" class="alignnone size-large wp-image-937" srcset="/files/2013/09/portlandia_coffee-224x300.jpg 224w, /files/2013/09/portlandia_coffee-767x1024.jpg 767w, /files/2013/09/portlandia_coffee.jpg 800w" sizes="(max-width: 640px) 100vw, 640px" /></a></p>

<p>Yep, that&#8217;s right. A slice of Portlandia. Got this bag of espresso from Cafe Myriad, a rather upscale coffee joint. I think it was 15 dollars. A small bag like this is good for 30 cups or so. A keurig k-pack is <a href="https://www.keurig.ca/coffee/africana-organic-fair-trade-coffee-k-cup-van-houtte">$17.45 for 24</a>. I&#8217;d say I&#8217;m still ahead. If you&#8217;re on a tighter budget you can get fair trade beans for cheaper ($10 a pound?) from Santropol in Montr&eacute;al. Or whatever. Even generic stuff is probably fine (though I encourage fair trade if you can possibly afford it).</p>

<p>And what do I do with the waste? The only waste product of the Bialetti filter is coffee grinds. If I happened to live in a borough of Montr&eacute;al with composting, I could dump it there. Unfortunately I don&#8217;t (if you live in NDG, please vote for <a href="http://projetmontreal.org">these people</a> in the upcoming municipal election; municipal composting is part of their platform, amongst other awesomeness) so I have a vermicompost. My morning ritual is dump yesterday&#8217;s coffee grinds into this bin:</p>

<p><a href="/files/2013/09/vermicompost_pic.jpg"><img src="/files/2013/09/vermicompost_pic-1024x934.jpg" alt="vermicompost_pic" width="640" height="583" class="alignnone size-large wp-image-935" srcset="/files/2013/09/vermicompost_pic-300x273.jpg 300w, /files/2013/09/vermicompost_pic-1024x934.jpg 1024w, /files/2013/09/vermicompost_pic.jpg 1560w" sizes="(max-width: 640px) 100vw, 640px" /></a></p>

<p>&#8230; and then my numerous worms do the work of turning it into beautiful soil which I use in my <a href="https://plus.google.com/photos/112599231040201259540/albums/5891369648488530945">balcony garden</a> to grow tomotatos, kale, swiss chard, basil, and oregano.</p>

<p>What I want to emphasize most of all is that my ritual <em>takes very little time</em>. Scraping out and cleaning my Bialetti in the worm compost bin takes around minute. Refilling it with water and coffee takes maybe 30 seconds. Yes, once a year I have to take the worm trailings out of my vermicompost bin. That takes longer (maybe 30 minutes to an hour) but it&#8217;s a once a year thing and you avoid having to go to the store to buy fertilizer. Less waste. Way better coffee. Only a marginally more time spent. To me, this is a no-brainer.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/BIXI.html">BIXI</a>, <a href="/tags/Data-Visualization.html">Data Visualization</a>, <a href="/tags/Nixi.html">Nixi</a></span></p>
    <h2><a href='/blog/2013/08/nixi-update/'>NIXI Update</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Aug 25th, 2013</p>
  </header>

<p>I&#8217;ve been working on a new, mobile friendly version of <a href="http://nixi.ca/">Nixi</a> on-and-off for the past year and a bit. I&#8217;m not sure when it&#8217;s ever going to be finished, so I thought I might as well post the work-in-progress, which has these noteworthy improvements:</p>

<ul>
 <li>Even faster than before (using the <a href="http://getbootstrap.com">Bootstrap</a> library behind the scenes, no longer using slow canvas library to update map)</li>
 <li>Sexier graphics (thanks to the aforementioned Bootstrap library)</li>
 <li>Now uses client side URLs to keep track of state as you navigate through the site. This allows you to bookmark a favorite spot (e.g. your home) and then go back to it later. For example, <a href="http://nixi.ca/#/cities/montreal/places/5605%20avenue%20de%20Gaspe">this link</a> will give you a list of BIXI docks near <a href="http://www.station-c.com/">Station C</a>, the coworking space I belong to.</li></ul>

<p>If you use <a href="http://bixi.com">BIXI</a> at all, check it out and let me know what you think!</p>

<p><a href="/files/2013/08/nixi-screenshot.png"> <img src="/files/2013/08/nixi-screenshot-1024x672.png" alt="nixi screenshot" width="640" height="420" class="alignnone size-large wp-image-927" srcset="/files/2013/08/nixi-screenshot-300x196.png 300w, /files/2013/08/nixi-screenshot-1024x672.png 1024w, /files/2013/08/nixi-screenshot.png 1266w" sizes="(max-width: 640px) 100vw, 640px" /></a></p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Android.html">Android</a>, <a href="/tags/Eideticker.html">Eideticker</a>, <a href="/tags/FirefoxOS.html">FirefoxOS</a>, <a href="/tags/Mozilla.html">Mozilla</a>, <a href="/tags/Time.html">Time</a></span></p>
    <h2><a href='/blog/2013/07/simple-command-line-ntp-client-for-android-and-firefoxos/'>Simple command-line ntp client for Android and FirefoxOS</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Jul 8th, 2013</p>
  </header>

<p>Today I did a quick port of Larry Doolittle&#8217;s <a href="http://doolittle.icarus.com/ntpclient/">ntpclient program</a> to Android and FirefoxOS. Basically this lets you easily synchronize your device&#8217;s time to that of a central server. Yes, there&#8217;s lots and lots of Android &#8220;applications&#8221; which let you do this, but I wanted to be able to do this from the command line because that&#8217;s how I roll. If you&#8217;re interested, source and instructions are here:</p>

<p><a href="https://github.com/wlach/ntpclient-android">https://github.com/wlach/ntpclient-android</a></p>

<p>For those curious, no, I didn&#8217;t just do this for fun. For next quarter, we want to write some Eideticker-based responsiveness tests for FirefoxOS and Android. For example, how long does it take from the time you tap on an icon in the homescreen on FirefoxOS to when the application is fully loaded? Or on Android, how long does it take to see a full list of sites in the awesomebar from the time you tap on the URL field and enter your search term?</p>

<p>Because an Eideticker test run involves two different machines (a host machine which controls the device and captures video of it in action, as well as the device itself), we need to use timestamps to really understand when and how events are being sent to the device. To do that reliably, we really need some easy way of synchronizing time between two machines (or at least accounting for the difference in their clocks, which amounts to about the same thing). NTP struck me as being the easiest, most standard way of doing this.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>, <a href="/tags/FirefoxOS.html">FirefoxOS</a>, <a href="/tags/Mozilla.html">Mozilla</a></span></p>
    <h2><a href='/blog/2013/05/proof-of-concept-eideticker-dashboard-for-firefoxos/'>Proof of concept Eideticker dashboard for FirefoxOS</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> May 6th, 2013</p>
  </header>

<p><em>[ For more information on the Eideticker software I&#8217;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>I just put up a proof of concept Eideticker dashboard for FirefoxOS <a href="http://eideticker.wrla.ch/b2g">here</a>. Right now it has two days worth of data, manually sampled from an Unagi device running b2g18. Right now there are two tests: one the measures the &#8220;speed&#8221; of the contacts application scrolling, another that measures the amount of time it takes for the contacts application to be fully loaded.</p>

<p>For those not already familiar with it, Eideticker is a benchmarking suite which captures live video data coming from a device and analyzes it to determine performance. This lets us get data which is more representative of actual user experience (as opposed to an oft artificial benchmark). For example, Eideticker measures contacts startup as taking anywhere between 3.5 seconds and 4.5 seconds, versus than the 0.5 to 1 seconds that the <a href="https://datazilla.mozilla.org/b2g/?branch=master&amp;#038;range=7&amp;#038;test=cold_load_time&amp;#038;app_list=contacts&amp;#038;app=contacts&amp;#038;gaia_rev=114bf216de0a19f7&amp;#038;gecko_rev=9c0de2afd22a8476">existing datazilla benchmarks</a> show. What accounts for the difference? If you step through an eideticker-captured video, you can see that even though <em>something</em> appears very quickly, not all the contacts are displayed until the 3.5 second mark. There is a gap between an app being reported as &#8220;loaded&#8221; and it being fully available for use, which we had not been measuring until now.</p>

<p>At this point, I am most interested in hearing from FirefoxOS developers on new tests that would be interesting and useful to track performance of the system on an ongoing basis. I&#8217;d obviously prefer to focus on things which have been difficult to measure accurately through other means. My setup is rather fiddly right now, but hopefully soon we can get some useful numbers going on an ongoing basis, as we <a href="http://eideticker.wrla.ch">do already</a> for Firefox for Android.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Buddhism.html">Buddhism</a>, <a href="/tags/Meditation.html">Meditation</a>, <a href="/tags/zen.html">zen</a></span></p>
    <h2><a href='/blog/2013/04/further-meditative-practice/'>Further meditative practice</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Apr 28th, 2013</p>
  </header>

<center><a href="/files/2013/04/biodome.jpg"><img src="/files/2013/04/biodome-768x1024.jpg" alt="biodome" width="426" height="568" class="alignnone size-large wp-image-905" srcset="/files/2013/04/biodome-225x300.jpg 225w, /files/2013/04/biodome-768x1024.jpg 768w, /files/2013/04/biodome.jpg 1024w" sizes="(max-width: 426px) 100vw, 426px" /></a></center>

<p>Okay, remember <a href="http://wrla.ch/blog/2013/03/a-visit-to-the-montreal-zen-center/">last time</a> when I said I was going to continue my &#8220;sham of a human existence&#8221; and not commit to a Zen practice? Well, I came back to the idea sooner than I thought: the experience was just too compelling for me not to do some further exploration. In some strange coincidence, Hacker News had a <a href="https://news.ycombinator.com/item?id=5432713">great thread on meditation</a> just after I wrote my last blog entry, where a few people recommended a book called <a href="http://www.urbandharma.org/udharma4/mpe.html">Mindfulness in Plain English</a>. I figured doing meditation at home didn&#8217;t involve any kind of huge commitment (don&#8217;t like it? just stop!), so I decided to order it online and give it a try.</p>

<p>Mindfulness in Plain English is really fascinating stuff. It describes how to do a type of Vipassana (insight) meditation, which is practiced with a great deal of ritual in places like Thailand, India, and Sri Lanka. The book however, strips out most of the ritual and just gives you a set of techniques that is quite accessible for a (presumably) western audience. From what I can gather though, it seems like the goal of Vipassana is quite similar to that of Zen (enlightenment; release from attachment and dualism), though the methods and rituals around it are quite different (e.g. there are no koans). Perhaps it&#8217;s akin to the difference between GIMP and Photoshop: as those two programs are both aimed at the manipulation of images, both Vipassana and Zen are aimed at the manipulation of the mind. There are differences in the script of how to do so, but the overarching purpose is the same.</p>

<p>Regardless, the portion of the C method that the book describes is almost exactly that which I tried at the Zen workshop: sit still and pay attention to your breathing. There&#8217;s a few minor distinctions in terms of the suggested posture (the book recommends either sitting cross legged or in a lotus position vs. the kneeling posture I learnt at the workshop) and the focal point (Mindfulness recommends the tip of the nostrils). But essentially it&#8217;s the same stuff. Focus on the breath &#8212; counting it if necessary, rince, repeat.</p>

<p>As I mentioned before, this is actually <em>really hard</em> to do properly for being simple in concept. The mind keeps wandering and wandering on all sorts of tangents: plans, daydreams, even thoughts about the meditation itself. Where I found Mindfulness in Plain English helpful was in the advice it gave for dealing with this &#8220;monkey mind&#8221; phenomenon. The subject is dealt with throughout the book (with two chapters on it and nothing else), but all the advice boils down to &#8220;treat it as part of the meditation&#8221;. Don&#8217;t try to avoid it, just treat it as something to be aware of in the same way as breathing. Then once you have acknowledged it, move the attention back to the breath.</p>

<p>Mindfulness, as far as I can gather, is simply non-judgemental awareness of what we are doing (and what we are supposed to be doing). Every time a distraction is noticed, felt, and understood, you&#8217;ve just experienced some approximation of the end goal of the meditation. Like it is with other things (an exercise regimen, learning to play a musical instrument), every small victory should push you further and the path to where you want to go. With enough practice, it might just become part of your day-to-day experience.</p>

<p>Or so I&#8217;m told by the book. Up to now, I haven&#8217;t enjoyed any longlasting effects from meditation aside from (possibly?) a bit more mental clarity in my day-to-day tasks. But I&#8217;ve found the practice to be extremely interesting both from the point of view of understanding my own thought, as well as being rather relaxing in and of itself. So while I&#8217;m curious as to what comes next, I am happy enough with things as they are in the present. I&#8217;m planning to continue to meditate (20&ndash;30 minutes a day, 6 days a week), but also delve a bit deeper into the details and history of Zen and Vipasanna. More updates as appropriate.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>, <a href="/tags/FirefoxOS.html">FirefoxOS</a>, <a href="/tags/Mozilla.html">Mozilla</a></span></p>
    <h2><a href='/blog/2013/04/actual-useful-firefoxos-eideticker-results-at-last/'>Actual useful FirefoxOS Eideticker results at last</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Apr 22nd, 2013</p>
  </header>

<p>Another update on getting <a href="http://wrla.ch/blog/2013/02/eideticker-for-firefoxos/">Eideticker working with FirefoxOS</a>. Once again this is sort of high-level, looking forward to writing something more in-depth soon now that we have the basics working.</p>

<p>I finally got the last kinks out of the rig I was using to capture live video from FirefoxOS phones using the Point Grey devices last week. In order to make things reasonable I had to write some custom code to isolate the actual device screen from the rest of capture and a few other things. The setup looks interesting (reminds me a bit of something out of the War of the Worlds):</p>

<p><a href="/files/2013/04/eideticker-pointgrey-mounted.jpg"><img src="/files/2013/04/eideticker-pointgrey-mounted.jpg" alt="eideticker-pointgrey-mounted" width="512" height="683" class="alignnone size-full wp-image-894" srcset="/files/2013/04/eideticker-pointgrey-mounted-224x300.jpg 224w, /files/2013/04/eideticker-pointgrey-mounted.jpg 512w" sizes="(max-width: 512px) 100vw, 512px" /></a></p>

<p>Here&#8217;s some example video of a test I wrote up to measure the performance of contacts scrolling performance (measured at a very respectable 44 frames per second, in case you wondering):</p>

<video src="/files/eideticker/contacts-scrolling-pointgrey.webm" controls="controls"></video>

<p>Surprisingly enough, I didn&#8217;t wind up having to write up any code to compensate for a noisy image. Of course there&#8217;s a certain amount of variance in every frame depending on how much light is hitting the camera sensor at any particular moment, but apparently not enough to interfere with getting useful results in the tests I&#8217;ve been running.</p>

<p>Likely next step: Create some kind of chassis for mounting both the camera and device on a permanent basis (instead of an adhoc one on my desk) so we can start running these sorts of tests on a daily basis, much like we currently do with Android on the <a href="http://eideticker.wrla.ch">Eideticker Dashboard</a>.</p>

<p>As an aside, I&#8217;ve been really impressed with both the <a href="https://wiki.mozilla.org/Auto-tools/Projects/Marionette">Marionette</a> framework and the gaiatests python module that was written up for FirefoxOS. Writing the above test took just 5 minutes &#8212; and <a href="https://github.com/mozilla/eideticker/blob/master/src/tests/b2g/appscrolling/scroll.py">the code</a> is quite straightforward. Quite the pleasant change from my various efforts in Android automation.</p>

</article>

<article>
  <header>
    <p><span class="tags"><a href="/tags/email.html">email</a>, <a href="/tags/Free-Software.html">Free Software</a>, <a href="/tags/GNOME.html">GNOME</a></span></p>
    <h2><a href='/blog/2013/04/the-need-for-a-modern-open-source-email-client-and-geary-8217-s-fundraiser/'>The need for a modern open source email client and Geary&#8217;s fundraiser</a></h2>
    <p class='index-date'><span class="glyphicon glyphicon-time" aria-hidden="true"></span> Apr 19th, 2013</p>
  </header>

<div class="figure"><img src="http://www.yorba.org/images/igg/geary-2.png" alt="" />
 <p class="caption"></p></div>

<p>One of my frustrations with the Linux desktop is the lack of an email client that&#8217;s in the same league as GMail or Apple&#8217;s mail.app. <a href="https://www.mozilla.org/EN/thunderbird">Thunderbird</a> is ok as far as it goes (I use it for my day-to-day Mozilla correspondence) but I miss having a decent conversation view of email (yes, I tried the <a href="https://addons.mozilla.org/en-us/thunderbird/addon/gmail-conversation-view/">conversation view extension</a> &#8212; while impressive in some ways, it ultimately didn&#8217;t work particularly well for me) and the search functionality is rather slow and cumbersome. I&#8217;d like to be optimistic about these problems being fixed at some point&#8230; but after nearly 2 years of using the product without much visible improvement my expectation of that happening is rather low.</p>

<p>The <a href="http://yorba.org">Yorba</a> non-profit recently started a <a href="http://www.indiegogo.com/projects/geary-a-beautiful-modern-open-source-email-client">fundraiser</a> to work on the next edition of Geary, an email client which I hope will fill the niche that I&#8217;m talking about. It&#8217;s pretty rough around the edges still, but even at this early stage the conversation view is beautiful and more or less exactly what I want. The example of Shotwell (their photo management application) suggests that they know a thing or two about creating robust and useable software, not a common thing in this day and age. In any case, their pitch was compelling enough for me to donate a few dollars to the cause. If you care about having a great email experience that is completely under your control (and not that of an advertising or product company with their own agenda), then maybe you could too?</p>

</article>

<footer>
 <ul class="pagination">
  <li class="page-item"><a class="page-link" href="/index-7.html">
    <quote>&larr;</quote></a></li>
  <li class="page-item"><a class="page-link" href="/index.html">1</a></li>
  <li class="page-item"><a class="page-link" href="/index-2.html">2</a></li>
  <li class="page-item"><a class="page-link" href="/index-3.html">3</a></li>
  <li class="page-item"><a class="page-link" href="/index-4.html">4</a></li>
  <li class="page-item"><a class="page-link" href="/index-5.html">5</a></li>
  <li class="page-item"><a class="page-link" href="/index-6.html">6</a></li>
  <li class="page-item"><a class="page-link" href="/index-7.html">7</a></li>
  <li class="page-item active"><a class="page-link" href="/index-8.html">8</a></li>
  <li class="page-item"><a class="page-link" href="/index-9.html">9</a></li>
  <li class="page-item"><a class="page-link" href="/index-10.html">10</a></li>
  <li class="page-item"><a class="page-link" href="/index-11.html">11</a></li>
  <li class="page-item"><a class="page-link" href="/index-12.html">12</a></li>
  <li class="page-item"><a class="page-link" href="/index-13.html">13</a></li>
  <li class="page-item"><a class="page-link" href="/index-14.html">14</a></li>
  <li class="page-item"><a class="page-link" href="/index-15.html">15</a></li>
  <li class="page-item"><a class="page-link" href="/index-9.html">
    <quote>&rarr;</quote></a></li></ul></footer>
        </div>
      </div>
      <footer>
        <p>Site generated by <a href="https://github.com/greghendershott/frog">Frog</a>,
          using <a href="https://getbootstrap.com">Bootstrap</a>.</p>
        <p>Post content is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution 3.0 Unported License</a>.
      </footer>
    </div>
    <!-- </body> JS -->
    <script type="text/javascript" src="//code.jquery.com/jquery.min.js"></script>
    <script type="text/javascript" src="/js/bootstrap.min.js"></script>
  </body>
</html>