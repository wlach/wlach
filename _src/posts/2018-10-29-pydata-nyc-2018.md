    Title: pydata nyc 2018
    Date: 2018-10-29T09:19:23
    Tags: Data, Python

Went to [PyData NYC](https://pydata.org/nyc2018/) a couple weeks ago, and figured I ought to write up my
thoughts for the benefits of the others on my extended team. Why not publish as a blog
post while I'm at it?

This is actually the first conference I'd been to in my capacity as a "data engineer"
at Mozilla, a team I joined about a year and a half ago after specializing in the
same area on the (now-defunct) [a-team](https://wiki.mozilla.org/EngineeringProductivity).
I've felt a special affinity for the Python community, particularly its data science
offshoots (pandas, numpy, and jupyter notebooks) so it was great to finally go to a
conference that specializes in these topics.

Overall, the conference was a bit of a mix between people talking about the status
of their projects, theoretical talks on specific statistical approaches to data,
general talks on how people are doing "data science" (I would
say the largest majority of attendees at the conference were users of python data
science tools, rather than developers), and case studies of how people
are using python data science tools in their research or work. This being New York,
many (probably the majority) were using data science tools in fields like quantitative
finance, sales, marketing, and health care.

As a side note, it was really satisfying to be able to tell Mozilla's story about
how we collect and use data without violating the privacy of our users. This is
becoming more and more of an issue (especailly in Europe with the GPDR) and it
really makes me happy that we have a really positive story to tell, not
a bunch of dirty secrets that we need to hide.

In general I found the last two types of talks the most rewarding to go to: most of the work I do
at Mozilla currently involves larger-scale data where, I'm sad to say, Python is
usually not (currently) an applicable tool, at least not by itself (though maybe [iodide](https://iodide.io)
will help change that! see below). And I don't usually find a 60 minute talk really
enough time for me to be able to properly absorb new mathematical or statistical
concepts, though I can sometimes get little tidbits of information from them
that come in handy later.

Some talks that made an impression on me:

* [Open source and quantitative finance](https://pydata.org/nyc2018/schedule/presentation/83/): Keynote
  talk, was a great introduction to the paranoia of the world of quantitative finance.
  I think the main message was that things are gradually moving to a (slightly less)
  paranoid model where generally-useful modifications done to numerical/ml software as
  part of a trading platform may now be upstreamed... but my main takeaway is that I'm
  really glad I'm not working in that industry.
* [Words in Space](https://pydata.org/nyc2018/schedule/presentation/9/): Introduced
  an interesting-soundingl library called [Yellow Brick](http://www.scikit-yb.org/en/latest/) for visualizing the results
  of machine learning models.
* [Creating a data-driven product culture](https://pydata.org/nyc2018/schedule/presentation/2/):
  General talk on how to create a positive and useful data science culture at a company. I think
  Mozilla already checks most of the boxes outlined in the talk.
* [What Data Scientists Really Do](https://pydata.org/nyc2018/schedule/presentation/39/): Quite entertaining talk on the future of "data science",
  by Hugo Bowne-Anderson (who also has a [podcast](https://www.datacamp.com/community/podcast) which sounds cool). The most
  interesting takeaway from the talk was the speculation that within 10 years the term
  "data scientist" might have the same meaning as the word "webmaster" now. It's a
  hyper-generalist job description which will almost inevitably be split into a number
  of other more specialized roles.
* [Master Class: Bayesian Statistics](https://pydata.org/nyc2018/schedule/presentation/77/): This falls under the "technical talk which I couldn't
  grasp in 60 minutes" category, but I think I finally do understand a little bit more
  of what people mean when they say "Bayesian Statistics" now. It actually doesn't have much
  to do with [Baye's Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem), rather it seems to be more of a philosophical approach to
  data analysis which acknowledges the limitations of human capacity to understand the
  world and asks us to more explicitly state our assumptions when developing models (probably
  over-simplifying here). I think I can get behind that -- want to learn more. They
  provided a [bunch of material](https://betanalpha.github.io/workshops/pydata/) to work through,
  which I've been meaning to take a look at.
* [Data Science in Health Care: Beyond the Hype](https://pydata.org/nyc2018/schedule/presentation/30/):
  Great presentations in how data science can be used to improve health care outcomes. Lots of relevant
  insights that I think are also applicable to "product health" here at Mozilla. I
  particularly liked the way the presenter framed requirements when deciding whether or not
  to do a type of analysis: "if i knew [information], i would do [intervention], which would
  have [measurable outcome]"

Of course, this post wouldn't be complete without a mention of
[Mike Droettboom](http://droettboom.com/)'s [talk](https://pydata.org/nyc2018/schedule/presentation/3/)
on [iodide](https://iodide.io), a project I've been spending
some considerable cycles helping with over the last couple of quarters. I need to
write some longer thoughts on iodide at some point in the near future, but in a nutshell
it's a scientific notebook environment where the computational kernel lives entirely
inside the browser. It was well received and we had a great followup session
afterwards with people interested in using it for various things. Being able to show
a python environment in the browser which "just works", with no installation or other
steps makes a *great* tech demo. I'm really excited about the public launch of our
server-based environment, which will hopefully be coming in the next couple of months.
